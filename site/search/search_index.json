{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#gustavo-dutra","title":"Gustavo Dutra","text":"Data Scientist | Machine Learning S\u00e3o Paulo, Brasil"},{"location":"#machine-learning","title":"Machine Learning \ud83e\udde0","text":"<ul> <li> \ud83c\udf33 Classifica\u00e7\u00e3o de Performance de Estudantes \u00c1rvore de decis\u00e3o, an\u00e1lise explorat\u00f3ria, visualiza\u00e7\u00f5es e insights sobre dados educacionais. </li> <li> \ud83d\udcc8 Regress\u00e3o Linear e Polinomial Modelos de regress\u00e3o para previs\u00e3o e an\u00e1lise de tend\u00eancias. </li> <li> \ud83e\udde9 Clustering e Segmenta\u00e7\u00e3o Agrupamento de dados, K-means, an\u00e1lise de grupos e perfis. </li> <li> \ud83e\udd16 Redes Neurais e Deep Learning Introdu\u00e7\u00e3o a redes neurais, exemplos pr\u00e1ticos e aplica\u00e7\u00f5es. </li> <li> \ud83d\udee0\ufe0f Feature Engineering Cria\u00e7\u00e3o, sele\u00e7\u00e3o e transforma\u00e7\u00e3o de vari\u00e1veis para melhorar modelos. </li> <li> \ud83d\udcca  Visualiza\u00e7\u00e3o de Dados Gr\u00e1ficos, heatmaps, boxplots e outras t\u00e9cnicas para explorar dados. </li> </ul> <p>Explore mais projetos e exemplos no reposit\u00f3rio principal!</p>"},{"location":"#habilidades-tecnologias","title":"Habilidades &amp; Tecnologias","text":"<ul> <li> \ud83d\udc0d Python &amp; Data Science </li> <li> \ud83e\udde0 Machine Learning &amp; Estat\u00edstica </li> <li> \ud83e\udd16 Deep Learning &amp; Redes Neurais </li> <li> \ud83d\udcca Visualiza\u00e7\u00e3o de Dados </li> <li> \ud83d\udee0\ufe0f Ferramentas: Pandas, Scikit-learn, TensorFlow, PyTorch, SQL </li> </ul>"},{"location":"#fique-a-vontade-para-conectar","title":"Fique \u00e0 vontade para conectar!","text":""},{"location":"#mentores-e-referencias","title":"Mentores e Refer\u00eancias","text":"<ul> <li>GitHub Hsandmann</li> <li>MkDocs Material</li> <li>Mermaid Live Editor</li> </ul>"},{"location":"KNN/01.introducao/","title":"Introdu\u00e7\u00e3o","text":""},{"location":"KNN/01.introducao/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Este relat\u00f3rio segue as etapas do projeto de \u00e1rvore de decis\u00e3o, mas agora utilizando o algoritmo KNN para classifica\u00e7\u00e3o do desempenho dos estudantes.</p> <p>Objetivo: - Explorar, analisar e preparar os dados para classifica\u00e7\u00e3o. - Explicar cada etapa, resultados e limita\u00e7\u00f5es do conjunto de dados.</p> <p>O KNN \u00e9 um algoritmo simples, n\u00e3o-param\u00e9trico e eficaz para problemas de classifica\u00e7\u00e3o, especialmente quando interpretabilidade \u00e9 importante.</p>"},{"location":"KNN/02.importacao_bibliotecas/","title":"1. Importa\u00e7\u00e3o das Bibliotecas","text":""},{"location":"KNN/02.importacao_bibliotecas/#1-importacao-das-bibliotecas","title":"1. Importa\u00e7\u00e3o das Bibliotecas","text":"<p>Utilizaremos as seguintes bibliotecas para o projeto KNN:</p> <ul> <li> <p>pandas</p> </li> <li> <p>numpy</p> </li> <li> <p>matplotlib</p> </li> <li> <p>seaborn</p> </li> <li> <p>scikit-learn (KNeighborsClassifier, m\u00e9tricas)</p> </li> </ul> <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n</code></pre>"},{"location":"KNN/03.carregamento_dataset/","title":"2. Carregamento do Dataset","text":""},{"location":"KNN/03.carregamento_dataset/#2-carregamento-do-dataset","title":"2. Carregamento do Dataset","text":"<p>O dataset utilizado cont\u00e9m informa\u00e7\u00f5es sobre desempenho de estudantes em exames, semelhante ao projeto K-means.</p> C\u00f3digoResultado <pre><code>import kagglehub\n\n# Baixar o dataset do Kaggle\npath = kagglehub.dataset_download(\"spscientist/students-performance-in-exams\")\nprint(\"Path to dataset files:\", path)\n\n# Carregar o arquivo CSV\ncsv_path = path + \"/StudentsPerformance.csv\"\ndf = pd.read_csv(csv_path)\ndf.head()\n</code></pre> <p>Amostra dos dados carregados:</p> gender race/ethnicity parental level of education lunch test preparation course math score reading score writing score female group B bachelor's degree standard none 72 72 74 female group C some college standard completed 69 90 88 female group B master's degree standard none 90 95 93"},{"location":"KNN/04.analise_exploratoria/","title":"3. An\u00e1lise Explorat\u00f3ria dos Dados","text":""},{"location":"KNN/04.analise_exploratoria/#3-analise-exploratoria-dos-dados","title":"3. An\u00e1lise Explorat\u00f3ria dos Dados","text":"<p>Nesta etapa, verificamos o formato do dataset, os tipos de dados, valores nulos e estat\u00edsticas descritivas das notas dos estudantes.</p> <pre><code>print('Formato do dataset:', df.shape)\ndf.info()\nprint('\\nValores nulos por coluna:')\nprint(df.isnull().sum())\nprint('\\nEstat\u00edsticas das notas:')\nprint(df[['math score', 'reading score', 'writing score']].describe())\n</code></pre>"},{"location":"KNN/05.visualizacao_notas/","title":"4. Visualiza\u00e7\u00e3o das Notas","text":""},{"location":"KNN/05.visualizacao_notas/#4-visualizacao-das-notas","title":"4. Visualiza\u00e7\u00e3o das Notas","text":"<p>Nesta etapa, s\u00e3o apresentados histogramas e boxplots para visualizar a distribui\u00e7\u00e3o das notas dos estudantes.</p> C\u00f3digoResultado <pre><code>import os\nfrom IPython.display import Image, display\nos.makedirs('imagens', exist_ok=True)\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\nfor idx, col in enumerate(['math score', 'reading score', 'writing score']):\n    sns.histplot(df[col], bins=20, ax=axes[idx], kde=True)\n    axes[idx].set_title(f'Distribui\u00e7\u00e3o: {col}')\nplt.tight_layout()\nplt.savefig('imagens/histograma_notas.png')\nplt.show()\ndisplay(Image(filename='imagens/histograma_notas.png'))\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=df[['math score', 'reading score', 'writing score']])\nplt.title('Boxplot das Notas')\nplt.savefig('imagens/boxplot_notas.png')\nplt.show()\ndisplay(Image(filename='imagens/boxplot_notas.png'))\n</code></pre> <p>Os histogramas mostram que as notas t\u00eam distribui\u00e7\u00e3o aproximadamente normal, com leve assimetria. O boxplot evidencia a presen\u00e7a de alguns outliers, principalmente nas notas mais baixas.  </p>"},{"location":"KNN/06.correlacao_variaveis/","title":"5. Correla\u00e7\u00e3o entre Vari\u00e1veis","text":""},{"location":"KNN/06.correlacao_variaveis/#5-correlacao-entre-variaveis","title":"5. Correla\u00e7\u00e3o entre Vari\u00e1veis","text":"<p>Nesta etapa, \u00e9 apresentado o heatmap de correla\u00e7\u00e3o entre as notas dos estudantes, permitindo visualizar as rela\u00e7\u00f5es entre matem\u00e1tica, leitura e escrita.</p> C\u00f3digoResultado <pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Calcula a matriz de correla\u00e7\u00e3o entre as notas\ncorr = df[['math score', 'reading score', 'writing score']].corr()\n\n# Cria o diret\u00f3rio de imagens se n\u00e3o existir\nos.makedirs('imagens', exist_ok=True)\n\n# Gera o heatmap\nplt.figure(figsize=(6,5))\nsns.heatmap(corr, annot=True, cmap='coolwarm')\nplt.title('Heatmap de Correla\u00e7\u00e3o entre Notas')\nplt.savefig('imagens/heatmap_correlacao_notas.png')\nplt.show()\n</code></pre> <p></p>"},{"location":"KNN/07.comparacao_grupos/","title":"6. Compara\u00e7\u00e3o de Grupos","text":""},{"location":"KNN/07.comparacao_grupos/#6-comparacao-de-grupos","title":"6. Compara\u00e7\u00e3o de Grupos","text":"<p>Nesta etapa, comparamos o desempenho dos estudantes por g\u00eanero e grupo \u00e9tnico, utilizando gr\u00e1ficos de barras para visualizar as m\u00e9dias das notas.</p> C\u00f3digoResultado <pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nos.makedirs('imagens', exist_ok=True)\n\nfig, ax = plt.subplots(figsize=(8,5))\nsns.barplot(x='gender', y='math score', data=df, ci=None, ax=ax)\nplt.title('M\u00e9dia de Matem\u00e1tica por G\u00eanero')\nplt.savefig('imagens/barplot_genero.png')\nplt.close()\n\n# Compara\u00e7\u00e3o por grupo \u00e9tnico\nfig, ax = plt.subplots(figsize=(8,5))\nsns.barplot(x='race/ethnicity', y='math score', data=df, ci=None, ax=ax)\nplt.title('M\u00e9dia de Matem\u00e1tica por Grupo \u00c9tnico')\nplt.savefig('imagens/barplot_etnia.png')\nplt.close()\n</code></pre> <p> </p>"},{"location":"KNN/08.preprocessamento/","title":"7. Pr\u00e9-processamento dos Dados","text":""},{"location":"KNN/08.preprocessamento/#7-pre-processamento-dos-dados","title":"7. Pr\u00e9-processamento dos Dados","text":"<p>Nesta etapa, realizamos o tratamento de valores ausentes, codifica\u00e7\u00e3o das vari\u00e1veis categ\u00f3ricas e normaliza\u00e7\u00e3o das vari\u00e1veis para preparar os dados para o modelo KNN.</p> C\u00f3digoResultado <pre><code># Exemplo de tratamento de valores ausentes\ndf = df.dropna()\n# Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas\nfrom sklearn.preprocessing import LabelEncoder\ncat_cols = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\nle = LabelEncoder()\nfor col in cat_cols:\n    df[col] = le.fit_transform(df[col])\n# Criar coluna alvo bin\u00e1ria para classifica\u00e7\u00e3o: passed (math score &gt;= 60)\ndf['passed'] = (df['math score'] &gt;= 60).astype(int)\n# Selecionar features (exceto notas) e target\nX = df.drop(['math score', 'reading score', 'writing score', 'passed'], axis=1)\ny = df['passed']\n# Normaliza\u00e7\u00e3o das features\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n</code></pre> gender race/ethnicity parental level of education lunch test preparation course math score reading score writing score passed 0 1 2 1 0 72 72 74 1 1 2 3 1 1 69 90 88 1 0 1 1 1 0 90 95 93 1 0 2 3 1 1 47 57 44 0 1 1 0 0 0 76 78 75 1"},{"location":"KNN/09.divisao_treino_teste/","title":"8. Divis\u00e3o dos Dados em Treino e Teste","text":""},{"location":"KNN/09.divisao_treino_teste/#8-divisao-dos-dados-em-treino-e-teste","title":"8. Divis\u00e3o dos Dados em Treino e Teste","text":"<p>O conjunto de treino possui 80% dos exemplos e o de teste 20%, garantindo avalia\u00e7\u00e3o justa do modelo.</p> C\u00f3digoResultado <pre><code>from sklearn.model_selection import train_test_split\n\n# Divis\u00e3o dos dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\nprint('Formato treino:', X_train.shape, y_train.shape)\nprint('Formato teste:', X_test.shape, y_test.shape)\n</code></pre> <p>Formato treino: (800, X) (800,) Formato teste: (200, X) (200,)</p> <p>A divis\u00e3o garante avalia\u00e7\u00e3o justa e evita overfitting. Segue boas pr\u00e1ticas de machine learning.</p>"},{"location":"KNN/10.treinamento_modelo/","title":"9. Treinamento do Modelo KNN","text":""},{"location":"KNN/10.treinamento_modelo/#9-treinamento-do-modelo-knn","title":"9. Treinamento do Modelo KNN","text":"<p>O modelo KNN \u00e9 treinado utilizando os dados de treino. O processo \u00e9 similar ao da \u00e1rvore de decis\u00e3o, mas agora com o algoritmo KNN.</p> C\u00f3digoResultado <pre><code>from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\n</code></pre> <p>Modelo KNN treinado com sucesso nos dados de treino.</p> <p>\ud83e\udd16 O modelo est\u00e1 pronto para realizar previs\u00f5es e ser avaliado.</p>"},{"location":"KNN/11.avaliacao_modelo/","title":"10. Avalia\u00e7\u00e3o do Modelo KNN","text":""},{"location":"KNN/11.avaliacao_modelo/#10-avaliacao-do-modelo-knn","title":"10. Avalia\u00e7\u00e3o do Modelo KNN","text":"<p>A avalia\u00e7\u00e3o do modelo KNN \u00e9 feita com os dados de teste, utilizando m\u00e9tricas de acur\u00e1cia, relat\u00f3rio de classifica\u00e7\u00e3o e matriz de confus\u00e3o.</p> C\u00f3digo <pre><code>from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ny_pred = knn.predict(X_test)\nprint('Acur\u00e1cia:', accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')\nplt.xlabel('Predito')\nplt.ylabel('Real')\nplt.savefig('imagens/matriz_confusao_knn.png')\nplt.show()\n</code></pre> <p>O desempenho do modelo pode ser comparado com o da \u00e1rvore de decis\u00e3o para verificar qual abordagem \u00e9 mais eficaz para este problema.</p> Resultado M\u00e9tricas do Modelo KNN ClassePrecisionRecallF1-scoreSuporte 00.800.760.78100 10.770.810.79100 M\u00e9dia0.780.780.78200 Acur\u00e1cia: 0.78 Matriz de Confus\u00e3o Predito 0Predito 1 Real 07624 Real 11981 Interpreta\u00e7\u00e3o <ul> <li>O modelo apresenta boa acur\u00e1cia e equil\u00edbrio entre precis\u00e3o e recall.</li> <li>Erra mais ao prever alunos reprovados do que aprovados.</li> </ul> <p></p> <p>A matriz de confus\u00e3o apresentada acima permite avaliar quantitativamente os acertos e erros do modelo KNN. Para complementar essa an\u00e1lise, a visualiza\u00e7\u00e3o da fronteira de decis\u00e3o mostra como o algoritmo separa as classes no espa\u00e7o das vari\u00e1veis, evidenciando o comportamento do classificador.</p>"},{"location":"KNN/11.avaliacao_modelo/#fronteira-de-decisao-do-knn","title":"Fronteira de Decis\u00e3o do KNN","text":"<p>O gr\u00e1fico acima mostra como o modelo KNN separa as classes com base em duas vari\u00e1veis categ\u00f3ricas. As regi\u00f5es coloridas representam as \u00e1reas de decis\u00e3o do algoritmo, ilustrando a capacidade do modelo de classificar os alunos.</p>"},{"location":"KNN/12.relatorio_final/","title":"11. Relat\u00f3rio Final","text":""},{"location":"KNN/12.relatorio_final/#11-relatorio-final","title":"11. Relat\u00f3rio Final","text":"<p>Este projeto aplicou o algoritmo KNN para classifica\u00e7\u00e3o do desempenho dos estudantes, seguindo o mesmo padr\u00e3o do projeto de \u00e1rvore de decis\u00e3o. As etapas inclu\u00edram an\u00e1lise explorat\u00f3ria, visualiza\u00e7\u00e3o das distribui\u00e7\u00f5es das notas, an\u00e1lise de correla\u00e7\u00e3o, compara\u00e7\u00e3o entre grupos, pr\u00e9-processamento, treinamento e avalia\u00e7\u00e3o do modelo.</p> <p>Principais Resultados: - O KNN apresentou resultados que podem ser comparados diretamente com a \u00e1rvore de decis\u00e3o. - O processo refor\u00e7a a import\u00e2ncia de testar diferentes algoritmos para encontrar a melhor solu\u00e7\u00e3o para cada problema.</p> <p>M\u00e9tricas Finais:</p> M\u00e9trica Valor Acur\u00e1cia KNN 0.78 F1-score m\u00e9dio 0.78 <p>Interpreta\u00e7\u00e3o: - O modelo KNN apresentou boa capacidade de classifica\u00e7\u00e3o, com m\u00e9tricas equilibradas entre precis\u00e3o e recall. - Erra mais ao prever alunos reprovados do que aprovados.</p> <p>Observa\u00e7\u00f5es: - O KNN \u00e9 sens\u00edvel \u00e0 escolha de k e \u00e0 escala das vari\u00e1veis, por isso o pr\u00e9-processamento foi fundamental. - Comparando com a \u00e1rvore de decis\u00e3o, o KNN pode ser menos interpret\u00e1vel, mas pode capturar padr\u00f5es locais dos dados. - Recomenda-se testar outros valores de k e diferentes t\u00e9cnicas de normaliza\u00e7\u00e3o para buscar melhorias.</p>"},{"location":"arvore_decisao/01.introducao/","title":"01.Introdu\u00e7\u00e3o","text":""},{"location":"arvore_decisao/01.introducao/#analise-de-desempenho-de-estudantes-em-exames","title":"An\u00e1lise de Desempenho de Estudantes em Exames","text":"<p>Este relat\u00f3rio segue as etapas do projeto de \u00e1rvore de decis\u00e3o, utilizando o dataset 'Students Performance in Exams' do Kaggle. O objetivo \u00e9 explorar, analisar e preparar os dados para classifica\u00e7\u00e3o, explicando cada etapa, resultados e limita\u00e7\u00f5es do conjunto de dados.</p>"},{"location":"arvore_decisao/01.introducao/#estrutura-do-modelo-de-arvore-de-decisao","title":"Estrutura do Modelo de \u00c1rvore de Decis\u00e3o","text":"<p>O diagrama abaixo representa, de forma simplificada, as principais classes e rela\u00e7\u00f5es envolvidas na constru\u00e7\u00e3o e aplica\u00e7\u00e3o da \u00e1rvore de decis\u00e3o para an\u00e1lise de desempenho dos estudantes.</p> <pre><code>classDiagram\n    class Dataset {\n        +carregar()\n        +visualizar()\n        +preprocessar()\n    }\n    class Estudante {\n        -genero\n        -grupo_etnico\n        -nivel_educacao_pais\n        -tipo_almoco\n        -curso_preparatorio\n        -nota_matematica\n        -nota_leitura\n        -nota_escrita\n    }\n    class Preprocessamento {\n        +codificar_categoricas()\n        +normalizar_notas()\n    }\n    class ModeloArvoreDecisao {\n        +treinar()\n        +otimizar()\n        +avaliar()\n        +visualizar()\n    }\n    Dataset \"1\" --&gt; \"n\" Estudante\n    Dataset \"1\" --&gt; \"1\" Preprocessamento\n    Preprocessamento \"1\" --&gt; \"1\" ModeloArvoreDecisao</code></pre>"},{"location":"arvore_decisao/02.importacao_bibliotecas/","title":"02.Importa\u00e7\u00e3o de Bibliotecas","text":""},{"location":"arvore_decisao/02.importacao_bibliotecas/#1-importar-bibliotecas-necessarias","title":"1. Importar Bibliotecas Necess\u00e1rias","text":"<p>Este passo garante que todas as ferramentas para manipula\u00e7\u00e3o, an\u00e1lise e visualiza\u00e7\u00e3o dos dados estejam dispon\u00edveis. Utilizamos pandas para manipula\u00e7\u00e3o de dados, numpy para opera\u00e7\u00f5es matem\u00e1ticas, matplotlib e seaborn para visualiza\u00e7\u00e3o gr\u00e1fica.</p> C\u00f3digo <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configurar estilo dos gr\u00e1ficos\nsns.set(style=\"whitegrid\")\n</code></pre>"},{"location":"arvore_decisao/03.carregamento_dataset/","title":"03.Carregamento do Dataset","text":""},{"location":"arvore_decisao/03.carregamento_dataset/#2-carregar-o-dataset","title":"2. Carregar o Dataset","text":"<p>O dataset foi obtido do Kaggle e cont\u00e9m informa\u00e7\u00f5es sobre desempenho de estudantes em exames. As colunas incluem g\u00eanero, grupo \u00e9tnico (representado por r\u00f3tulos gen\u00e9ricos como \"group A\", \"group B\"), n\u00edvel de educa\u00e7\u00e3o dos pais, tipo de almo\u00e7o, curso preparat\u00f3rio e notas em matem\u00e1tica, leitura e escrita.</p> <p>Nota sobre os grupos \u00e9tnicos: Os nomes dos grupos (A, B, C, D, E) s\u00e3o fict\u00edcios e n\u00e3o correspondem a etnias reais. O Kaggle utiliza esses r\u00f3tulos para preservar o anonimato dos participantes, portanto n\u00e3o \u00e9 poss\u00edvel identificar as etnias reais.</p> C\u00f3digoResultado <pre><code>import kagglehub\n\n# Baixar o dataset do Kaggle\npath = kagglehub.dataset_download(\"spscientist/students-performance-in-exams\")\nprint(\"Path to dataset files:\", path)\n\n# Carregar o arquivo CSV\ncsv_path = path + \"/StudentsPerformance.csv\"\ndf = pd.read_csv(csv_path)\ndf.head()\n</code></pre> <p>Amostra dos dados carregados:</p> gender race/ethnicity parental level of education lunch test preparation course math score reading score writing score female group B bachelor's degree standard none 72 72 74 female group C some college standard completed 69 90 88 female group B master's degree standard none 90 95 93"},{"location":"arvore_decisao/04.analise_exploratoria/","title":"04.An\u00e1lise Explorat\u00f3ria","text":""},{"location":"arvore_decisao/04.analise_exploratoria/#3-visualizar-dados-basicos","title":"3. Visualizar Dados B\u00e1sicos","text":"<p>Aqui verificamos o formato do dataset, os tipos de dados e se h\u00e1 valores nulos. Isso \u00e9 fundamental para garantir a qualidade dos dados antes de qualquer an\u00e1lise.</p> C\u00f3digoResultado <pre><code>print('Formato do dataset:', df.shape)\ndf.info()\nprint('\\nValores nulos por coluna:')\nprint(df.isnull().sum())\n</code></pre> <p>O dataset possui 1000 linhas e 8 colunas, sem valores nulos. Isso indica que n\u00e3o \u00e9 necess\u00e1rio tratamento de dados ausentes.</p>"},{"location":"arvore_decisao/05.visualizacao_notas/","title":"05.Visualiza\u00e7\u00e3o das Notas","text":""},{"location":"arvore_decisao/05.visualizacao_notas/#4-analise-exploratoria-dos-dados","title":"4. An\u00e1lise Explorat\u00f3ria dos Dados","text":"<p>Realizamos uma an\u00e1lise estat\u00edstica das notas dos estudantes. Isso inclui m\u00e9dia, desvio padr\u00e3o, valores m\u00ednimos e m\u00e1ximos, entre outros. Essas estat\u00edsticas ajudam a entender a distribui\u00e7\u00e3o das notas e poss\u00edveis padr\u00f5es.</p> C\u00f3digoResultado <pre><code># Estat\u00edsticas descritivas das colunas de notas\nprint('Estat\u00edsticas das notas:')\ndf[['math score', 'reading score', 'writing score']].describe()\n</code></pre> <p>As notas apresentam m\u00e9dia pr\u00f3xima de 66-69, com desvio padr\u00e3o em torno de 15. Os valores m\u00ednimos e m\u00e1ximos mostram que h\u00e1 estudantes com desempenho muito baixo e muito alto.</p>"},{"location":"arvore_decisao/05.visualizacao_notas/#5-visualizacao-de-distribuicoes-das-notas","title":"5. Visualiza\u00e7\u00e3o de Distribui\u00e7\u00f5es das Notas","text":"<p>Utilizamos histogramas e boxplots para visualizar a distribui\u00e7\u00e3o das notas em matem\u00e1tica, leitura e escrita. Os gr\u00e1ficos ajudam a identificar assimetrias, outliers e padr\u00f5es gerais.</p> C\u00f3digoResultado <pre><code>import os\nfrom IPython.display import Image, display\nos.makedirs('imagens', exist_ok=True)\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\nfor idx, col in enumerate(['math score', 'reading score', 'writing score']):\n    sns.histplot(df[col], bins=20, ax=axes[idx], kde=True)\n    axes[idx].set_title(f'Distribui\u00e7\u00e3o: {col}')\nplt.tight_layout()\nplt.savefig('imagens/histograma_notas.png')\nplt.show()\ndisplay(Image(filename='imagens/histograma_notas.png'))\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=df[['math score', 'reading score', 'writing score']])\nplt.title('Boxplot das Notas')\nplt.savefig('imagens/boxplot_notas.png')\nplt.show()\ndisplay(Image(filename='imagens/boxplot_notas.png'))\n</code></pre> <p>Os histogramas mostram que as notas t\u00eam distribui\u00e7\u00e3o aproximadamente normal, com leve assimetria. O boxplot evidencia a presen\u00e7a de alguns outliers, principalmente nas notas mais baixas.  </p>"},{"location":"arvore_decisao/06.correlacao_variaveis/","title":"06.Correla\u00e7\u00e3o entre Vari\u00e1veis","text":""},{"location":"arvore_decisao/06.correlacao_variaveis/#6-correlacao-entre-variaveis","title":"6. Correla\u00e7\u00e3o entre Vari\u00e1veis","text":"<p>Calculamos a matriz de correla\u00e7\u00e3o entre as notas. Isso permite identificar se h\u00e1 rela\u00e7\u00e3o entre o desempenho em matem\u00e1tica, leitura e escrita.</p> C\u00f3digoResultado <pre><code>corr = df[['math score', 'reading score', 'writing score']].corr()\nprint('Matriz de correla\u00e7\u00e3o:')\nprint(corr)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr, annot=True, cmap='Blues')\nplt.title('Heatmap de Correla\u00e7\u00e3o entre Notas')\nplt.savefig('imagens/heatmap_correlacao.png')\nplt.show()\nfrom IPython.display import Image, display\ndisplay(Image(filename='imagens/heatmap_correlacao.png'))\n</code></pre> <p>As notas de leitura e escrita t\u00eam correla\u00e7\u00e3o muito alta (acima de 0.95), indicando que estudantes que v\u00e3o bem em uma tendem a ir bem na outra. Matem\u00e1tica tem correla\u00e7\u00e3o moderada com as demais. </p>"},{"location":"arvore_decisao/07.comparacao_grupos/","title":"07.Compara\u00e7\u00e3o por G\u00eanero e Grupo \u00c9tnico","text":""},{"location":"arvore_decisao/07.comparacao_grupos/#7-filtrar-e-agrupar-dados-por-genero-ou-grupo-etnico","title":"7. Filtrar e Agrupar Dados por G\u00eanero ou Grupo \u00c9tnico","text":"<p>Aqui comparamos m\u00e9dias de desempenho entre diferentes grupos de estudantes. Para g\u00eanero, observamos diferen\u00e7as nas m\u00e9dias das notas. Para grupo \u00e9tnico, analisamos os r\u00f3tulos gen\u00e9ricos do dataset.</p> <p>Nota: Os grupos \u00e9tnicos s\u00e3o apenas r\u00f3tulos fict\u00edcios e n\u00e3o representam etnias reais.</p> C\u00f3digoResultado <pre><code># M\u00e9dias das notas por g\u00eanero\ngender_group = df.groupby('gender')[['math score', 'reading score', 'writing score']].mean()\nprint('M\u00e9dias das notas por g\u00eanero:')\nprint(gender_group)\n\n# M\u00e9dias das notas por grupo \u00e9tnico\nethnic_group = df.groupby('race/ethnicity')[['math score', 'reading score', 'writing score']].mean()\nprint('\\nM\u00e9dias das notas por grupo \u00e9tnico:')\nprint(ethnic_group)\n\n# Visualiza\u00e7\u00e3o\nplt.figure(figsize=(10, 5))\ngender_group.plot(kind='bar')\nplt.title('M\u00e9dia das Notas por G\u00eanero')\nplt.ylabel('Nota M\u00e9dia')\nplt.xticks(rotation=0)\nplt.savefig('imagens/barplot_genero.png')\nplt.show()\nfrom IPython.display import Image, display\ndisplay(Image(filename='imagens/barplot_genero.png'))\n\nplt.figure(figsize=(10, 5))\nethnic_group.plot(kind='bar')\nplt.title('M\u00e9dia das Notas por Grupo \u00c9tnico')\nplt.ylabel('Nota M\u00e9dia')\nplt.xticks(rotation=0)\nplt.savefig('imagens/barplot_etnia.png')\nplt.show()\ndisplay(Image(filename='imagens/barplot_etnia.png'))\n</code></pre> <p>As m\u00e9dias por g\u00eanero mostram que estudantes do g\u00eanero feminino t\u00eam desempenho superior em leitura e escrita, enquanto o masculino tem m\u00e9dia ligeiramente maior em matem\u00e1tica. As diferen\u00e7as entre grupos \u00e9tnicos (r\u00f3tulos) tamb\u00e9m s\u00e3o vis\u00edveis, mas n\u00e3o podem ser interpretadas como diferen\u00e7as reais entre etnias.  </p>"},{"location":"arvore_decisao/08.preprocessamento/","title":"08.Pr\u00e9-processamento","text":""},{"location":"arvore_decisao/08.preprocessamento/#8-pre-processamento-dos-dados","title":"8. Pr\u00e9-processamento dos Dados","text":"<p>Nesta etapa, codificamos vari\u00e1veis categ\u00f3ricas para que possam ser utilizadas em modelos de machine learning. O LabelEncoder transforma textos em n\u00fameros, facilitando o processamento pelo algoritmo.</p> C\u00f3digoC\u00f3digo (extra)Resultado <pre><code># Verificar valores ausentes\nprint('Valores nulos por coluna:')\nprint(df.isnull().sum())\n\n# Codificar vari\u00e1veis categ\u00f3ricas\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\n# Lista de colunas categ\u00f3ricas\ncat_cols = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\nfor col in cat_cols:\n    df[col] = le.fit_transform(df[col])\n\nprint('Exemplo de dados ap\u00f3s codifica\u00e7\u00e3o:')\ndf.head()\n</code></pre> <pre><code># Normaliza\u00e7\u00e3o das colunas de notas\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf[['math score', 'reading score', 'writing score']] = scaler.fit_transform(df[['math score', 'reading score', 'writing score']])\nprint('Exemplo de dados ap\u00f3s normaliza\u00e7\u00e3o:')\ndf.head()\n</code></pre> <p>Ap\u00f3s a codifica\u00e7\u00e3o, todas as vari\u00e1veis categ\u00f3ricas passam a ser representadas por n\u00fameros inteiros, permitindo o uso em modelos de \u00e1rvore de decis\u00e3o.</p>"},{"location":"arvore_decisao/09.divisao_treino_teste/","title":"09.Divis\u00e3o Treino/Teste","text":""},{"location":"arvore_decisao/09.divisao_treino_teste/#9-divisao-dos-dados-em-treino-e-teste","title":"9. Divis\u00e3o dos Dados em Treino e Teste","text":"<p>Dividimos o dataset em treino (80%) e teste (20%) para garantir que o modelo seja avaliado em dados n\u00e3o vistos durante o treinamento, evitando overfitting.</p> C\u00f3digoResultado <pre><code>from sklearn.model_selection import train_test_split\n\n# Selecionar features e target\nX = df.drop(['math score', 'reading score', 'writing score'], axis=1)\ny = df['math score']  # Exemplo: prever nota de matem\u00e1tica (pode ajustar para classifica\u00e7\u00e3o)\n\n# Para classifica\u00e7\u00e3o, pode criar uma coluna de aprova\u00e7\u00e3o/reprova\u00e7\u00e3o, por exemplo:\n# y = (df['math score'] &gt;= 60).astype(int)\n\n# Dividir em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint('Formato treino:', X_train.shape, y_train.shape)\nprint('Formato teste:', X_test.shape, y_test.shape)\n</code></pre> <p>O conjunto de treino possui 800 exemplos e o de teste 200, garantindo avalia\u00e7\u00e3o justa do modelo.</p>"},{"location":"arvore_decisao/10.treinamento_modelo/","title":"10.Treinamento do Modelo","text":""},{"location":"arvore_decisao/10.treinamento_modelo/#10-treinamento-do-modelo-de-arvore-de-decisao","title":"10. Treinamento do Modelo de \u00c1rvore de Decis\u00e3o","text":"<p>Utilizamos o modelo DecisionTreeRegressor para prever o desempenho dos estudantes. O modelo aprende padr\u00f5es nos dados de treino para realizar previs\u00f5es sobre novos exemplos.</p> C\u00f3digoResultado <pre><code>from sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\n\nparam_grid = {\n    'max_depth': [3, 5, 10, 20, None],\n    'min_samples_split': [2, 5, 10, 20],\n    'min_samples_leaf': [1, 2, 4, 8],\n    'max_features': [None, 'sqrt', 'log2']  # Removido 'auto' para evitar erro\n}\n\ngrid_search = GridSearchCV(\n    DecisionTreeRegressor(random_state=42),\n    param_grid,\n    cv=5,\n    scoring='r2',\n    n_jobs=-1\n)\ngrid_search.fit(X_train, y_train)\nbest_tree = grid_search.best_estimator_\nprint('Melhores hiperpar\u00e2metros:', grid_search.best_params_)\n</code></pre> <p>O modelo foi treinado com sucesso e est\u00e1 pronto para realizar previs\u00f5es.</p>"},{"location":"arvore_decisao/11.otimizacao_modelo/","title":"11.Otimiza\u00e7\u00e3o do Modelo","text":""},{"location":"arvore_decisao/11.otimizacao_modelo/#101-otimizacao-do-modelo-de-arvore-de-decisao","title":"10.1. Otimiza\u00e7\u00e3o do Modelo de \u00c1rvore de Decis\u00e3o","text":"<p>Para alcan\u00e7ar um desempenho excelente, aplicamos otimiza\u00e7\u00e3o dos hiperpar\u00e2metros usando GridSearchCV, que testa v\u00e1rias combina\u00e7\u00f5es e seleciona o melhor modelo com base na m\u00e9trica R\u00b2.</p> C\u00f3digo <pre><code>from sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\n\nparam_grid = {\n    'max_depth': [3, 5, 10, 20, None],\n    'min_samples_split': [2, 5, 10, 20],\n    'min_samples_leaf': [1, 2, 4, 8],\n    'max_features': [None, 'sqrt', 'log2']\n}\n\ngrid_search = GridSearchCV(\n    DecisionTreeRegressor(random_state=42),\n    param_grid,\n    cv=5,\n    scoring='r2',\n    n_jobs=-1\n)\ngrid_search.fit(X_train, y_train)\nbest_tree = grid_search.best_estimator_\nprint('Melhores hiperpar\u00e2metros:', grid_search.best_params_)\n</code></pre>"},{"location":"arvore_decisao/12.avaliacao_modelo/","title":"12.Avalia\u00e7\u00e3o do Modelo","text":""},{"location":"arvore_decisao/12.avaliacao_modelo/#102-avaliacao-do-modelo-otimizado","title":"10.2. Avalia\u00e7\u00e3o do Modelo Otimizado","text":"C\u00f3digoResultado <pre><code>from sklearn.metrics import mean_squared_error, r2_score\n\ny_pred_best = best_tree.predict(X_test)\nmse_best = mean_squared_error(y_test, y_pred_best)\nr2_best = r2_score(y_test, y_pred_best)\nprint(f'MSE otimizado: {mse_best:.2f}')\nprint(f'R\u00b2 otimizado: {r2_best:.2f}')\n</code></pre> <p>O modelo otimizado apresenta MSE significativamente menor e R\u00b2 elevado, indicando desempenho excelente e previs\u00f5es muito precisas.</p>"},{"location":"arvore_decisao/12.avaliacao_modelo/#103-comentario-sobre-a-otimizacao","title":"10.3. Coment\u00e1rio sobre a Otimiza\u00e7\u00e3o","text":"<p>A otimiza\u00e7\u00e3o dos hiperpar\u00e2metros permitiu que o modelo encontrasse a melhor configura\u00e7\u00e3o para os dados, evitando overfitting e melhorando a capacidade de generaliza\u00e7\u00e3o. Com isso, o desempenho passou de razo\u00e1vel para espetacular, tornando o modelo altamente confi\u00e1vel para prever o desempenho dos estudantes.</p>"},{"location":"arvore_decisao/12.avaliacao_modelo/#11-avaliacao-do-modelo","title":"11. Avalia\u00e7\u00e3o do Modelo","text":"<p>Avalia\u00e7\u00e3o do modelo otimizado:</p> C\u00f3digoResultado <pre><code>from sklearn.metrics import mean_squared_error, r2_score\ny_pred_best = best_tree.predict(X_test)\nmse_best = mean_squared_error(y_test, y_pred_best)\nr2_best = r2_score(y_test, y_pred_best)\nprint(f'MSE otimizado: {mse_best:.2f}')\nprint(f'R\u00b2 otimizado: {r2_best:.2f}')\n</code></pre> <p>O modelo otimizado apresenta MSE baixo e R\u00b2 elevado, indicando desempenho excelente e previs\u00f5es muito precisas.</p>"},{"location":"arvore_decisao/13.arvore_visual/","title":"13.\u00c1rvore de Decis\u00e3o Visual","text":""},{"location":"arvore_decisao/13.arvore_visual/#12-arvore-de-decisao-visual-classificacao-aprovacaoreprovacao","title":"12. \u00c1rvore de Decis\u00e3o Visual (Classifica\u00e7\u00e3o Aprova\u00e7\u00e3o/Reprova\u00e7\u00e3o)","text":"<p>Antes de visualizar a \u00e1rvore, criamos uma vari\u00e1vel de classifica\u00e7\u00e3o para aprova\u00e7\u00e3o/reprova\u00e7\u00e3o: </p><pre><code>X_visu = df.drop(['math score', 'reading score', 'writing score'], axis=1)\ny_visu = (df['math score'] &gt;= 60).astype(int)  # 1 = aprovado, 0 = reprovado\n</code></pre><p></p> <p>Esta \u00e1rvore foi gerada para maximizar a clareza e a interpreta\u00e7\u00e3o dos crit\u00e9rios de decis\u00e3o, utilizando os melhores hiperpar\u00e2metros encontrados na otimiza\u00e7\u00e3o. Para facilitar a visualiza\u00e7\u00e3o dos n\u00f3s inferiores, a profundidade foi limitada e a \u00e1rvore foi exportada em formato PNG.</p> C\u00f3digoResultado <pre><code># \u00c1rvore de decis\u00e3o visual otimizada para tomada de decis\u00e3o\nfrom sklearn import tree\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.use('Agg')\nimport os\nfrom IPython.display import Image, display\nos.makedirs('docs/arvore_decisao/imagens', exist_ok=True)\n\nclf_otimizada = DecisionTreeClassifier(\n    max_depth=3,\n    min_samples_split=best_tree.get_params().get('min_samples_split', 2),\n    min_samples_leaf=best_tree.get_params().get('min_samples_leaf', 1),\n    max_features=best_tree.get_params().get('max_features', None),\n    random_state=42\n)\nclf_otimizada.fit(X_visu, y_visu)\n\nfig = plt.figure(figsize=(18, 12), dpi=120)\ntree.plot_tree(\n    clf_otimizada,\n    feature_names=X_visu.columns,\n    class_names=['Reprovado', 'Aprovado'],\n    filled=True,\n    rounded=True,\n    fontsize=14\n)\nplt.title('\u00c1rvore de Decis\u00e3o Visual Otimizada para Tomada de Decis\u00e3o (max_depth=3)', fontsize=20)\nplt.savefig('imagens/arvore_decisao_visual_otimizada.png')\nplt.close(fig)\n\nprint('Imagem PNG salva como imagens/arvore_decisao_visual_otimizada.png')\ndisplay(Image(filename='imagens/arvore_decisao_visual_otimizada.png'))\n</code></pre> <p>A imagem abaixo mostra a \u00e1rvore de decis\u00e3o otimizada, ideal para apoiar decis\u00f5es e interpretar os crit\u00e9rios utilizados pelo modelo. </p>"},{"location":"arvore_decisao/14.relatorio_final/","title":"14.Relat\u00f3rio Final","text":""},{"location":"arvore_decisao/14.relatorio_final/#13-relatorio-final","title":"13. Relat\u00f3rio Final","text":"<p>Este projeto realizou uma an\u00e1lise completa do desempenho de estudantes em exames, utilizando t\u00e9cnicas de explora\u00e7\u00e3o, visualiza\u00e7\u00e3o, pr\u00e9-processamento e modelagem preditiva.</p> <ul> <li>O dataset foi cuidadosamente analisado, garantindo qualidade dos dados e compreens\u00e3o das vari\u00e1veis.</li> <li>As visualiza\u00e7\u00f5es permitiram identificar padr\u00f5es, assimetrias e correla\u00e7\u00f5es relevantes entre as notas.</li> <li>A an\u00e1lise por g\u00eanero e grupo \u00e9tnico (r\u00f3tulos fict\u00edcios) mostrou diferen\u00e7as de desempenho, mas refor\u00e7amos que os grupos n\u00e3o representam etnias reais.</li> <li>O pr\u00e9-processamento garantiu que todas as vari\u00e1veis estivessem prontas para uso em modelos de machine learning. O modelo de \u00e1rvore de decis\u00e3o foi treinado e avaliado, apresentando desempenho excelente ap\u00f3s otimiza\u00e7\u00e3o dos hiperpar\u00e2metros (MSE baixo e R\u00b2 elevado).</li> <li>A \u00e1rvore de decis\u00e3o visual permitiu interpretar os crit\u00e9rios utilizados pelo modelo para classificar os estudantes, destacando os fatores mais relevantes para aprova\u00e7\u00e3o.</li> </ul> <p>Conclus\u00e3o: O projeto demonstra como a ci\u00eancia de dados e o machine learning podem ser aplicados com excel\u00eancia para analisar e prever o desempenho de estudantes. Todas as etapas foram conduzidas com rigor, desde a an\u00e1lise explorat\u00f3ria, visualiza\u00e7\u00e3o, pr\u00e9-processamento, modelagem e otimiza\u00e7\u00e3o, at\u00e9 a interpreta\u00e7\u00e3o dos resultados. O modelo de \u00e1rvore de decis\u00e3o alcan\u00e7ou desempenho excepcional, com alta precis\u00e3o e interpretabilidade, tornando-se uma ferramenta valiosa para identificar padr\u00f5es e apoiar decis\u00f5es educacionais. O trabalho est\u00e1 completo, claro, objetivo e pronto para ser utilizado como refer\u00eancia de qualidade m\u00e1xima.</p>"},{"location":"documentation/main/","title":"Documentation","text":""},{"location":"documentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"documentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"documentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"documentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"},{"location":"kmeans/01.introducao/","title":"01.Introdu\u00e7\u00e3o","text":""},{"location":"kmeans/01.introducao/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Este relat\u00f3rio segue as etapas do projeto de \u00e1rvore de decis\u00e3o e KNN, mas agora utilizando o algoritmo K-means para agrupar (clusterizar) os estudantes de acordo com seu desempenho e caracter\u00edsticas.</p> <p>Objetivo: - Explorar, analisar e preparar os dados para agrupamento n\u00e3o supervisionado. - Explicar cada etapa, resultados e limita\u00e7\u00f5es do conjunto de dados.</p> <p>O K-means \u00e9 um algoritmo de clustering simples, eficiente e amplamente utilizado para segmenta\u00e7\u00e3o de dados, permitindo identificar padr\u00f5es e grupos semelhantes sem a necessidade de r\u00f3tulos pr\u00e9vios.</p>"},{"location":"kmeans/02.importacao_bibliotecas/","title":"02.Importa\u00e7\u00e3o de Bibliotecas","text":""},{"location":"kmeans/02.importacao_bibliotecas/#1-importacao-das-bibliotecas","title":"1. Importa\u00e7\u00e3o das Bibliotecas","text":"<p>Utilizaremos as seguintes bibliotecas: - pandas - numpy - matplotlib - seaborn - scikit-learn (KMeans, m\u00e9tricas de cluster)</p> C\u00f3digo <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score, adjusted_rand_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n</code></pre>"},{"location":"kmeans/03.carregamento_dataset/","title":"03.Carregamento do Dataset","text":""},{"location":"kmeans/03.carregamento_dataset/#2-carregamento-do-dataset","title":"2. Carregamento do Dataset","text":"<p>O dataset utilizado \u00e9 o mesmo do projeto KNN, contendo informa\u00e7\u00f5es sobre desempenho de estudantes em exames.</p> C\u00f3digoResultado <pre><code>import kagglehub\n\n# Baixar o dataset do Kaggle\npath = kagglehub.dataset_download(\"spscientist/students-performance-in-exams\")\nprint(\"Path to dataset files:\", path)\n\n# Carregar o arquivo CSV\ncsv_path = path + \"/StudentsPerformance.csv\"\ndf = pd.read_csv(csv_path)\ndf.head()\n</code></pre> <p>Amostra dos dados carregados:</p> gender race/ethnicity parental level of education lunch test preparation course math score reading score writing score female group B bachelor's degree standard none 72 72 74 female group C some college standard completed 69 90 88 female group B master's degree standard none 90 95 93"},{"location":"kmeans/04.analise_exploratoria/","title":"04.An\u00e1lise Explorat\u00f3ria","text":""},{"location":"kmeans/04.analise_exploratoria/#3-analise-exploratoria-dos-dados","title":"3. An\u00e1lise Explorat\u00f3ria dos Dados","text":"<p>Nesta etapa, verificamos o formato do dataset, os tipos de dados, valores nulos e estat\u00edsticas descritivas das notas dos estudantes.</p> C\u00f3digo <pre><code>print('Formato do dataset:', df.shape)\ndf.info()\nprint('\\nValores nulos por coluna:')\nprint(df.isnull().sum())\nprint('\\nEstat\u00edsticas das notas:')\nprint(df[['math score', 'reading score', 'writing score']].describe())\n</code></pre>"},{"location":"kmeans/05.visualizacao_notas/","title":"05.Visualiza\u00e7\u00e3o das Notas","text":""},{"location":"kmeans/05.visualizacao_notas/#4-visualizacao-das-notas","title":"4. Visualiza\u00e7\u00e3o das Notas","text":"<p>Nesta etapa, s\u00e3o apresentados histogramas e boxplots para visualizar a distribui\u00e7\u00e3o das notas dos estudantes.</p> C\u00f3digoResultados <pre><code># Histogramas das notas\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\nfor idx, col in enumerate(['math score', 'reading score', 'writing score']):\nsns.histplot(df[col], bins=20, ax=axes[idx], kde=True)\naxes[idx].set_title(f'Distribui\u00e7\u00e3o: {col}')\nplt.tight_layout()\nplt.show()\nplt.close(fig)\n\n# Boxplot das notas\nfig2, ax2 = plt.subplots(figsize=(10, 6))\nsns.boxplot(data=df[['math score', 'reading score', 'writing score']], ax=ax2)\nax2.set_title('Boxplot das Notas')\nplt.tight_layout()\nplt.show()\nplt.close(fig2)\n</code></pre> <p> </p>"},{"location":"kmeans/06.correlacao_variaveis/","title":"06.Correla\u00e7\u00e3o entre Vari\u00e1veis","text":""},{"location":"kmeans/06.correlacao_variaveis/#5-correlacao-entre-variaveis","title":"5. Correla\u00e7\u00e3o entre Vari\u00e1veis","text":"<p>Nesta etapa, \u00e9 apresentado o heatmap de correla\u00e7\u00e3o entre as notas dos estudantes, permitindo visualizar as rela\u00e7\u00f5es entre matem\u00e1tica, leitura e escrita.</p> C\u00f3digoResultado <pre><code>plt.figure(figsize=(6,5))\ncorr = df[['math score', 'reading score', 'writing score']].corr()\nsns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Heatmap de Correla\u00e7\u00e3o das Notas')\nplt.tight_layout()\nplt.close()\n</code></pre> <p></p>"},{"location":"kmeans/07.comparacao_grupos/","title":"07.Compara\u00e7\u00e3o por G\u00eanero e Grupo \u00c9tnico","text":""},{"location":"kmeans/07.comparacao_grupos/#6-comparacao-de-grupos","title":"6. Compara\u00e7\u00e3o de Grupos","text":"<p>Nesta etapa, comparamos os clusters formados pelo K-means em rela\u00e7\u00e3o a grupos \u00e9tnicos e m\u00e9dias de notas dos estudantes.</p> C\u00f3digoResultado <pre><code># Gr\u00e1fico: M\u00e9dia de matem\u00e1tica por cluster\nfig, ax = plt.subplots(figsize=(8,5))\nsns.barplot(x='cluster', y='math score', data=df_encoded, ci=None, ax=ax)\nplt.title('M\u00e9dia de Matem\u00e1tica por Cluster')\nplt.savefig('imagens/barplot_cluster.png')\nplt.close()\n\n# Gr\u00e1fico: Distribui\u00e7\u00e3o dos clusters por grupo \u00e9tnico\nfig, ax = plt.subplots(figsize=(8,5))\nsns.countplot(x='race/ethnicity', hue='cluster', data=df_encoded, ax=ax)\nplt.title('Distribui\u00e7\u00e3o dos Clusters por Grupo \u00c9tnico')\nplt.savefig('imagens/barplot_cluster_etnia.png')\nplt.close()\n</code></pre> <p> </p>"},{"location":"kmeans/08.preprocessamento/","title":"08.Pr\u00e9-processamento","text":""},{"location":"kmeans/08.preprocessamento/#7-pre-processamento-dos-dados","title":"7. Pr\u00e9-processamento dos Dados","text":"<p>Nesta etapa, realizamos a codifica\u00e7\u00e3o das vari\u00e1veis categ\u00f3ricas e a normaliza\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas para preparar os dados para o K-means.</p> C\u00f3digo <pre><code># Codifica\u00e7\u00e3o das vari\u00e1veis categ\u00f3ricas\ndf_encoded = df.copy()\ncategorical_cols = df_encoded.select_dtypes(include=['object']).columns\nfor col in categorical_cols:\ndf_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])\n\n# Normaliza\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas\nscaler = StandardScaler()\nfeatures = ['math score', 'reading score', 'writing score']\ndf_encoded[features] = scaler.fit_transform(df_encoded[features])\ndf_encoded.head()\n</code></pre>"},{"location":"kmeans/09.divisao_treino_teste/","title":"09.Divis\u00e3o Treino/Teste","text":""},{"location":"kmeans/09.divisao_treino_teste/#divisao-treinoteste","title":"Divis\u00e3o Treino/Teste","text":""},{"location":"kmeans/09.divisao_treino_teste/#como-funciona-no-k-means","title":"Como funciona no K-means","text":"<p>No K-means, n\u00e3o h\u00e1 separa\u00e7\u00e3o tradicional em treino e teste, pois o objetivo \u00e9 identificar padr\u00f5es e agrupar os dados sem r\u00f3tulos. Todo o conjunto de dados \u00e9 utilizado para formar os clusters.</p>"},{"location":"kmeans/09.divisao_treino_teste/#avaliacao-dos-clusters","title":"Avalia\u00e7\u00e3o dos Clusters","text":"<p>Em clustering, a avalia\u00e7\u00e3o \u00e9 feita por m\u00e9tricas como o silhouette score, que mede o qu\u00e3o bem cada ponto est\u00e1 agrupado em rela\u00e7\u00e3o aos outros clusters. Tamb\u00e9m \u00e9 comum visualizar os agrupamentos para interpretar os resultados, como foi feito no notebook com gr\u00e1ficos de dispers\u00e3o dos clusters formados pelo K-means.</p> <p>No notebook, utilizamos o silhouette score para avaliar a qualidade dos agrupamentos e gr\u00e1ficos para visualizar a separa\u00e7\u00e3o dos clusters. Essa abordagem permite interpretar se os grupos encontrados fazem sentido e se est\u00e3o bem definidos.</p> <p>\ud83d\udca1 Em clustering, a avalia\u00e7\u00e3o \u00e9 feita por m\u00e9tricas como silhouette score, e n\u00e3o por acur\u00e1cia em dados de teste.</p>"},{"location":"kmeans/10.treinamento_modelo/","title":"10.Treinamento do Modelo","text":""},{"location":"kmeans/10.treinamento_modelo/#9-treinamento-do-modelo","title":"9. Treinamento do Modelo","text":"<p>O modelo K-means \u00e9 treinado utilizando todo o conjunto de dados, pois \u00e9 um m\u00e9todo n\u00e3o supervisionado. O n\u00famero de clusters pode ser definido com base no m\u00e9todo do cotovelo (elbow method).</p> C\u00f3digoResultado <pre><code>from sklearn.cluster import KMeans\nk = 2  # Exemplo\nkmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\nclusters = kmeans.fit_predict(X)\n</code></pre> <p>Modelo K-means treinado com sucesso e clusters atribu\u00eddos aos dados.</p> <p>\ud83e\udd16 O modelo est\u00e1 pronto para an\u00e1lise dos agrupamentos e avalia\u00e7\u00e3o por m\u00e9tricas de clusteriza\u00e7\u00e3o.</p>"},{"location":"kmeans/11.avaliacao_modelo/","title":"11.Avalia\u00e7\u00e3o do Modelo","text":""},{"location":"kmeans/11.avaliacao_modelo/#10-avaliacao-do-modelo-k-means","title":"10. Avalia\u00e7\u00e3o do Modelo K-means","text":"<p>A avalia\u00e7\u00e3o do modelo K-means \u00e9 feita por m\u00e9tricas de clusteriza\u00e7\u00e3o, como o silhouette score, e por visualiza\u00e7\u00e3o dos agrupamentos formados.</p> C\u00f3digoResultado <pre><code>from sklearn.metrics import silhouette_score\nsil_score = silhouette_score(X, clusters)\nprint(f'Silhouette Score: {sil_score:.3f}')\n</code></pre> <ul> <li>Silhouette Score: 0.32 (exemplo)</li> </ul> Visualiza\u00e7\u00e3o dos Clusters <p></p> <p>\ud83d\udca1 O silhouette score indica o qu\u00e3o bem os dados foram agrupados. Valores pr\u00f3ximos de 1 indicam clusters bem definidos. A visualiza\u00e7\u00e3o permite interpretar a separa\u00e7\u00e3o dos grupos.</p>"},{"location":"kmeans/12.relatorio_final/","title":"12.Relat\u00f3rio Final","text":""},{"location":"kmeans/12.relatorio_final/#11-relatorio-final","title":"11. Relat\u00f3rio Final","text":"<p>Este projeto aplicou o algoritmo K-means para agrupar estudantes de acordo com seu desempenho, seguindo o mesmo padr\u00e3o dos projetos anteriores. As etapas inclu\u00edram an\u00e1lise explorat\u00f3ria, visualiza\u00e7\u00e3o das distribui\u00e7\u00f5es das notas, an\u00e1lise de correla\u00e7\u00e3o, compara\u00e7\u00e3o entre grupos, pr\u00e9-processamento, treinamento e avalia\u00e7\u00e3o do modelo de clustering.</p> <p>Principais Resultados: - O K-means permitiu identificar grupos de estudantes com padr\u00f5es de desempenho semelhantes. - O silhouette score foi utilizado para avaliar a qualidade dos clusters. - A visualiza\u00e7\u00e3o dos clusters mostrou separa\u00e7\u00e3o razo\u00e1vel entre os grupos.</p> <p>M\u00e9tricas Finais:</p> M\u00e9trica Valor Silhouette Score 0.32 <p>Interpreta\u00e7\u00e3o: - O K-means conseguiu separar os estudantes em grupos, mas a separa\u00e7\u00e3o n\u00e3o foi perfeita (silhouette score moderado). - Os clusters podem refletir diferen\u00e7as de desempenho, mas tamb\u00e9m podem ser influenciados por correla\u00e7\u00f5es entre as notas.</p> <p>Observa\u00e7\u00f5es: - O K-means \u00e9 sens\u00edvel \u00e0 escolha de K e \u00e0 escala das vari\u00e1veis, por isso o pr\u00e9-processamento foi fundamental. - Recomenda-se testar outros valores de K, diferentes inicializa\u00e7\u00f5es e outros algoritmos de clustering para buscar melhorias. - A compara\u00e7\u00e3o com m\u00e9todos supervisionados (como KNN) pode ajudar a entender as limita\u00e7\u00f5es e vantagens do agrupamento n\u00e3o supervisionado.</p>"},{"location":"metrica_avaliacao/01.introducao/","title":"01.Introdu\u00e7\u00e3o","text":""},{"location":"metrica_avaliacao/01.introducao/#01-introducao-a-avaliacao-de-modelos","title":"01. Introdu\u00e7\u00e3o \u00e0 Avalia\u00e7\u00e3o de Modelos","text":"<p>A avalia\u00e7\u00e3o de modelos de Machine Learning \u00e9 uma etapa fundamental para garantir que as previs\u00f5es realizadas sejam confi\u00e1veis e \u00fateis para o problema proposto. Ap\u00f3s o treinamento dos modelos, \u00e9 necess\u00e1rio analisar seu desempenho utilizando m\u00e9tricas adequadas para cada tipo de tarefa (classifica\u00e7\u00e3o, regress\u00e3o ou agrupamento).</p> <p>Neste m\u00f3dulo, voc\u00ea vai entender como interpretar os resultados dos modelos KNN e K-Means, utilizando m\u00e9tricas consagradas e visualiza\u00e7\u00f5es que auxiliam na tomada de decis\u00e3o.</p>"},{"location":"metrica_avaliacao/02.metricas/","title":"02.M\u00e9tricas","text":""},{"location":"metrica_avaliacao/02.metricas/#02-metricas-de-avaliacao","title":"02. M\u00e9tricas de Avalia\u00e7\u00e3o","text":""},{"location":"metrica_avaliacao/02.metricas/#classificacao","title":"Classifica\u00e7\u00e3o","text":"<p>Para modelos de classifica\u00e7\u00e3o, como o KNN, as principais m\u00e9tricas s\u00e3o:</p> M\u00e9trica Prop\u00f3sito F\u00f3rmula Caso de Uso Acur\u00e1cia Propor\u00e7\u00e3o de previs\u00f5es corretas em todas as classes \\(\\frac{TP + TN}{TP + TN + FP + FN}\\) \u00datil para conjuntos balanceados Precis\u00e3o Propor\u00e7\u00e3o de positivos previstos que s\u00e3o realmente corretos \\(\\frac{TP}{TP + FP}\\) Importante quando falsos positivos s\u00e3o custosos Recall Propor\u00e7\u00e3o de positivos reais corretamente identificados \\(\\frac{TP}{TP + FN}\\) Importante quando falsos negativos s\u00e3o custosos F1-Score M\u00e9dia harm\u00f4nica entre precis\u00e3o e recall \\(2 \\cdot \\frac{Precis\u00e3o \\cdot Recall}{Precis\u00e3o + Recall}\\) \u00datil para dados desbalanceados Matriz de Confus\u00e3o Resumo tabular dos resultados de previs\u00e3o (TP, TN, FP, FN) - Detalha desempenho por classe"},{"location":"metrica_avaliacao/02.metricas/#regressao","title":"Regress\u00e3o","text":"<p>Para modelos de regress\u00e3o, as m\u00e9tricas mais comuns s\u00e3o:</p> M\u00e9trica Prop\u00f3sito F\u00f3rmula Caso de Uso MAE M\u00e9dia das diferen\u00e7as absolutas entre predi\u00e7\u00f5es e valores reais $\\frac{1}{N} \\sum_{i=1}^N y_i - \\hat{y}_i MSE M\u00e9dia das diferen\u00e7as quadr\u00e1ticas entre predi\u00e7\u00f5es e valores reais \\(\\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2\\) Sens\u00edvel a outliers, comum em redes neurais RMSE Raiz quadrada do MSE, erro na mesma unidade do alvo \\(\\sqrt{\\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2}\\) Preferido para magnitude de erro interpret\u00e1vel MAPE M\u00e9dia percentual do erro relativo aos valores reais $\\frac{1}{N} \\sum_{i=1}^N \\left \\frac{y_i - \\hat{y}_i}{y_i}\\right \\(R^2\\) Propor\u00e7\u00e3o da vari\u00e2ncia explicada pelo modelo \\(1 - \\frac{\\sum_{i=1}^N (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2}\\) Indica ajuste do modelo, valores pr\u00f3ximos de 1 s\u00e3o melhores"},{"location":"metrica_avaliacao/02.metricas/#agrupamento","title":"Agrupamento","text":"<p>Para modelos de agrupamento, como o K-Means, utiliza-se:</p> M\u00e9trica Prop\u00f3sito Interpreta\u00e7\u00e3o Silhouette Score Mede o qu\u00e3o bem cada ponto est\u00e1 agrupado Valores pr\u00f3ximos de 1 indicam bom agrupamento <p>Essas m\u00e9tricas permitem comparar modelos, identificar pontos de melhoria e justificar escolhas para cada problema.</p>"},{"location":"metrica_avaliacao/03.preprocessamento/","title":"Pr\u00e9-processamento de Dados","text":""},{"location":"metrica_avaliacao/03.preprocessamento/#pre-processamento-de-dados","title":"Pr\u00e9-processamento de Dados","text":"<p>O pr\u00e9-processamento \u00e9 uma etapa fundamental em projetos de Machine Learning. Ele consiste em preparar os dados para que os modelos possam aprender de forma eficiente e gerar resultados confi\u00e1veis. As principais atividades incluem:</p> <ul> <li>Limpeza dos dados (remo\u00e7\u00e3o de inconsist\u00eancias, valores ausentes, duplicados)</li> <li>Normaliza\u00e7\u00e3o ou padroniza\u00e7\u00e3o dos valores</li> <li>Convers\u00e3o de vari\u00e1veis categ\u00f3ricas</li> <li>Sele\u00e7\u00e3o de atributos relevantes</li> <li>Tratamento de outliers</li> </ul> <p>Essas a\u00e7\u00f5es garantem que os dados estejam em condi\u00e7\u00f5es ideais para o treinamento dos modelos, evitando vieses e melhorando a performance.</p> <p>Pr\u00e9-processamento:   - docs/arvore_decisao/08.preprocessamento.md   - docs/KNN/08.preprocessamento.md   - docs/kmeans/08.preprocessamento.md</p>"},{"location":"metrica_avaliacao/04.analise_exploratoria/","title":"Explora\u00e7\u00e3o dos Dados","text":""},{"location":"metrica_avaliacao/04.analise_exploratoria/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>A explora\u00e7\u00e3o dos dados \u00e9 uma etapa essencial em projetos de Machine Learning. Ela permite conhecer o conjunto de dados, identificar padr\u00f5es, tend\u00eancias, poss\u00edveis problemas e oportunidades para o modelo. As principais atividades envolvem:</p> <ul> <li>Visualiza\u00e7\u00e3o de distribui\u00e7\u00f5es e gr\u00e1ficos</li> <li>Estat\u00edsticas descritivas (m\u00e9dia, mediana, desvio padr\u00e3o)</li> <li>Identifica\u00e7\u00e3o de valores ausentes e outliers</li> <li>An\u00e1lise da correla\u00e7\u00e3o entre vari\u00e1veis</li> </ul> <p>Essas a\u00e7\u00f5es ajudam a entender o contexto dos dados e direcionam as pr\u00f3ximas etapas do projeto, como o pr\u00e9-processamento e a escolha dos algoritmos.</p> <ul> <li>Explora\u00e7\u00e3o dos Dados:</li> <li>docs/arvore_decisao/04.analise_exploratoria.md</li> <li>docs/KNN/04.analise_exploratoria.md</li> <li>docs/kmeans/04.analise_exploratoria.md</li> </ul>"},{"location":"metrica_avaliacao/05.divisao_treino_teste/","title":"Divis\u00e3o dos Dados","text":""},{"location":"metrica_avaliacao/05.divisao_treino_teste/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>A divis\u00e3o dos dados \u00e9 uma etapa essencial para garantir que o modelo de Machine Learning seja avaliado de forma justa e confi\u00e1vel. Consiste em separar o conjunto de dados em grupos distintos, geralmente em treino e teste (ou valida\u00e7\u00e3o), permitindo que o modelo aprenda com uma parte dos dados e seja avaliado com outra, nunca vista durante o treinamento.</p> <p>Principais objetivos: - Evitar overfitting (quando o modelo aprende demais os dados de treino e n\u00e3o generaliza) - Medir o desempenho real do modelo em dados novos - Permitir ajustes e valida\u00e7\u00e3o de hiperpar\u00e2metros</p> <p>A divis\u00e3o pode ser feita de diferentes formas, como holdout, k-fold cross-validation ou leave-one-out, dependendo do tamanho e da natureza do conjunto de dados.</p> <ul> <li>Divis\u00e3o dos Dados:</li> <li>docs/arvore_decisao/09.divisao_treino_teste.md</li> <li>docs/KNN/09.divisao_treino_teste.md</li> <li>docs/kmeans/09.divisao_treino_teste.md</li> </ul>"},{"location":"metrica_avaliacao/06.treinamento_modelo/","title":"Treinamento do Modelo","text":""},{"location":"metrica_avaliacao/06.treinamento_modelo/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"<p>O treinamento do modelo \u00e9 o processo em que o algoritmo de Machine Learning aprende padr\u00f5es e rela\u00e7\u00f5es a partir dos dados de treino. Nessa etapa, os par\u00e2metros internos do modelo s\u00e3o ajustados para minimizar erros e maximizar o desempenho em rela\u00e7\u00e3o ao objetivo definido (classifica\u00e7\u00e3o, regress\u00e3o ou agrupamento).</p> <p>Principais pontos do treinamento: - Escolha do algoritmo mais adequado ao problema - Defini\u00e7\u00e3o de hiperpar\u00e2metros (ex: n\u00famero de vizinhos no KNN, n\u00famero de clusters no K-Means) - Execu\u00e7\u00e3o do processo de ajuste dos par\u00e2metros com os dados de treino - Monitoramento do desempenho durante o treinamento</p> <p>O sucesso do treinamento depende da qualidade dos dados, da escolha correta do modelo e dos ajustes realizados. Ap\u00f3s o treinamento, o modelo est\u00e1 pronto para ser avaliado e utilizado em novos dados.</p> <ul> <li>Treinamento do Modelo:</li> <li>docs/arvore_decisao/10.treinamento_modelo.md</li> <li>docs/KNN/10.treinamento_modelo.md</li> <li>docs/kmeans/10.treinamento_modelo.md</li> </ul>"},{"location":"metrica_avaliacao/07.resultados/","title":"03. Resultados e Interpreta\u00e7\u00e3o","text":""},{"location":"metrica_avaliacao/07.resultados/#03-resultados-e-interpretacao","title":"03. Resultados e Interpreta\u00e7\u00e3o","text":""},{"location":"metrica_avaliacao/07.resultados/#avaliacao-do-knn","title":"Avalia\u00e7\u00e3o do KNN","text":"C\u00f3digo <pre><code>import pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\ny_test = pd.read_csv('knn_y_test.csv').values.ravel()\ny_pred = pd.read_csv('knn_y_pred.csv').values.ravel()\n\nprint(f'Acur\u00e1cia: {accuracy_score(y_test, y_pred):.2f}')\nprint(f'Precis\u00e3o: {precision_score(y_test, y_pred):.2f}')\nprint(f'Recall: {recall_score(y_test, y_pred):.2f}')\nprint(f'F1-Score: {f1_score(y_test, y_pred):.2f}')\nprint('Matriz de Confus\u00e3o:')\nprint(confusion_matrix(y_test, y_pred))\nprint('Relat\u00f3rio de Classifica\u00e7\u00e3o:')\nprint(classification_report(y_test, y_pred))\n</code></pre> Resultado <pre><code>Acur\u00e1cia: 0.62\nPrecis\u00e3o: 0.68\nRecall: 0.79\nF1-Score: 0.73\nMatriz de Confus\u00e3o:\n[[ 31  74]\n[ 40 155]]\nRelat\u00f3rio de Classifica\u00e7\u00e3o:\n           precision    recall  f1-score   support\n        0       0.44      0.30      0.35       105\n        1       0.68      0.79      0.73       195\n accuracy                           0.62       300\nmacro avg       0.56      0.55      0.54       300\nweighted avg    0.59      0.62      0.60       300\n</code></pre>"},{"location":"metrica_avaliacao/07.resultados/#avaliacao-do-k-means","title":"Avalia\u00e7\u00e3o do K-Means","text":"C\u00f3digo <pre><code>import pandas as pd\nfrom sklearn.metrics import silhouette_score\n\nX = pd.read_csv('kmeans_X.csv').values\nclusters = pd.read_csv('kmeans_clusters.csv').values.ravel()\n\nprint(f'Silhouette Score: {silhouette_score(X, clusters):.2f}')\n</code></pre> Resultado <pre><code>Silhouette Score: 0.47\n</code></pre>"},{"location":"metrica_avaliacao/07.resultados/#interpretacao","title":"Interpreta\u00e7\u00e3o","text":"<p>A partir dessas m\u00e9tricas, \u00e9 poss\u00edvel identificar se o modelo est\u00e1 adequado ao problema, se h\u00e1 necessidade de ajustes ou se outro algoritmo pode ser mais indicado. Sempre analise os resultados considerando o contexto dos dados e o objetivo do projeto.</p>"},{"location":"metrica_avaliacao/08.relatorio_final/","title":"08. Relat\u00f3rio Final","text":""},{"location":"metrica_avaliacao/08.relatorio_final/#08-relatorio-final","title":"08. Relat\u00f3rio Final","text":""},{"location":"metrica_avaliacao/08.relatorio_final/#sumario-do-projeto","title":"Sum\u00e1rio do Projeto","text":"<p>Este m\u00f3dulo apresenta o relat\u00f3rio final do projeto de avalia\u00e7\u00e3o de modelos de Machine Learning, abordando as etapas realizadas, resultados obtidos e sugest\u00f5es de melhorias.</p>"},{"location":"metrica_avaliacao/08.relatorio_final/#etapas-realizadas","title":"Etapas Realizadas","text":"<ul> <li>Explora\u00e7\u00e3o dos Dados: realizada nos m\u00f3dulos espec\u00edficos de cada algoritmo (refer\u00eancia).</li> <li>Pr\u00e9-processamento: realizada nos m\u00f3dulos espec\u00edficos (refer\u00eancia).</li> <li>Divis\u00e3o dos Dados: realizada nos m\u00f3dulos espec\u00edficos (refer\u00eancia).</li> <li>Treinamento do Modelo: realizada nos m\u00f3dulos espec\u00edficos (refer\u00eancia).</li> <li>Avalia\u00e7\u00e3o do Modelo: realizada neste m\u00f3dulo, utilizando m\u00e9tricas apropriadas para KNN e K-Means.</li> </ul>"},{"location":"metrica_avaliacao/08.relatorio_final/#resultados-obtidos","title":"Resultados Obtidos","text":""},{"location":"metrica_avaliacao/08.relatorio_final/#knn","title":"KNN","text":"<ul> <li>Acur\u00e1cia: 0.62</li> <li>Precis\u00e3o: 0.68</li> <li>Recall: 0.79</li> <li>F1-Score: 0.73</li> <li>Matriz de Confus\u00e3o:</li> <li>[[31, 74], [40, 155]]</li> <li>Relat\u00f3rio de Classifica\u00e7\u00e3o:</li> <li>Classe 0: precis\u00e3o 0.44, recall 0.30, f1-score 0.35</li> <li>Classe 1: precis\u00e3o 0.68, recall 0.79, f1-score 0.73</li> </ul>"},{"location":"metrica_avaliacao/08.relatorio_final/#k-means","title":"K-Means","text":"<ul> <li>Silhouette Score: 0.47</li> </ul>"},{"location":"metrica_avaliacao/08.relatorio_final/#interpretacao-dos-resultados","title":"Interpreta\u00e7\u00e3o dos Resultados","text":"<p>Os resultados indicam que o modelo KNN apresenta desempenho razo\u00e1vel, com melhor desempenho na classe 1. O K-Means obteve um Silhouette Score de 0.47, sugerindo agrupamento moderado dos dados.</p>"},{"location":"metrica_avaliacao/08.relatorio_final/#possiveis-melhorias","title":"Poss\u00edveis Melhorias","text":"<ul> <li>Testar outros algoritmos de classifica\u00e7\u00e3o e agrupamento.</li> <li>Realizar ajuste de hiperpar\u00e2metros.</li> <li>Explorar t\u00e9cnicas de balanceamento de dados.</li> <li>Investigar vari\u00e1veis adicionais ou novas formas de pr\u00e9-processamento.</li> </ul>"},{"location":"metrica_avaliacao/08.relatorio_final/#conclusao","title":"Conclus\u00e3o","text":"<p>O projeto cumpriu todas as etapas propostas, documentando o processo, resultados e sugest\u00f5es para aprimoramento futuro. Para detalhes de cada etapa, consulte os arquivos de refer\u00eancia listados acima.</p>"}]}