---
hide:
- toc
---

# 05. Divis√£o de Dados: Estrat√©gias Avan√ßadas para Valida√ß√£o Robusta

## üéØ A Funda√ß√£o da Valida√ß√£o Cient√≠fica

A divis√£o de dados √© **o alicerce da confiabilidade** em Machine Learning. Uma divis√£o inadequada pode tornar at√© mesmo os modelos mais sofisticados in√∫teis na pr√°tica, gerando falsa confian√ßa e resultados irreproduziveis.

## üî¨ Princ√≠pios Cient√≠ficos Fundamentais

### **1. Independ√™ncia Estat√≠stica** üìä

| Princ√≠pio | Implementa√ß√£o | Viola√ß√£o Comum | Consequ√™ncia |
|-----------|---------------|----------------|--------------|
| **IID (Independent, Identically Distributed)** | Random sampling | Dados temporais misturados | Data leakage |
| **Representatividade** | Stratified sampling | Amostras enviesadas | Generaliza√ß√£o falha |
| **N√£o-vazamento** | Split antes preprocessing | Features vazadas | Overfitting severo |

### **2. Estrat√©gias por Tipo de Problema** üé≠

```mermaid
graph TD
    A[Tipo de Dados] --> B[Tabular Est√°tico]
    A --> C[S√©ries Temporais]
    A --> D[Dados Espaciais]
    
    B --> E[Random Split]
    B --> F[Stratified Split]
    
    C --> G[Temporal Split]
    C --> H[Time Series CV]
    
    D --> I[Spatial Blocking]
    D --> J[Group-based Split]
```

## üìä T√©cnicas de Divis√£o Avan√ßadas

### **1. Hold-out Estratificado** üéØ

| Configura√ß√£o | Train | Validation | Test | Uso Recomendado |
|--------------|-------|------------|------|-----------------|
| **Cl√°ssico** | 70% | 15% | 15% | Datasets > 10k amostras |
| **Conservador** | 60% | 20% | 20% | Datasets < 1k amostras |
| **Research** | 80% | 10% | 10% | Prototipagem r√°pida |
| **Production** | 70% | 0% | 30% | Deploy final |

### **2. Cross-Validation Avan√ßado** üîÑ

| T√©cnica | K-folds | Repeti√ß√µes | Vantagem | Desvantagem |
|---------|---------|------------|----------|-------------|
| **K-Fold** | 5-10 | 1 | Padr√£o ouro | Pode ter vari√¢ncia |
| **Repeated K-Fold** | 5 | 3-5 | Mais est√°vel | Computacionalmente caro |
| **Stratified K-Fold** | 5-10 | 1 | Mant√©m propor√ß√µes | S√≥ para classifica√ß√£o |
| **Leave-One-Out** | n-1 | 1 | M√°ximo treino | Muito caro, alta vari√¢ncia |

### **3. Valida√ß√£o para Dados Desbalanceados** ‚öñÔ∏è

```python
# Estratifica√ß√£o avan√ßada
‚úÖ StratifiedKFold: Mant√©m propor√ß√£o exata
‚úÖ StratifiedShuffleSplit: Propor√ß√£o + aleatoriedade
‚úÖ RepeatedStratifiedKFold: M√∫ltiplas execu√ß√µes
‚ùå Random split: Pode criar folds sem classe minorit√°ria
```

## ‚è∞ Dados Temporais: Cuidados Especiais

### **Temporal Split** üìÖ

| M√©todo | Descri√ß√£o | Vantagem | Limita√ß√£o |
|--------|-----------|----------|-----------|
| **Chronological** | Split por data fixa | Realista | Pouco treino |
| **Rolling Window** | Janela deslizante | Mais dados | Computacionalmente caro |
| **Expanding Window** | Janela crescente | Aprende de todo hist√≥rico | Concept drift |
| **Blocked CV** | Blocos temporais | Balanceado | Gaps artificiais |

### **Time Series Cross-Validation** ‚è≥

```python
# Exemplo de configura√ß√£o temporal
Train:   [1-100] [1-200] [1-300] [1-400]
Valid:   [101-150] [201-250] [301-350] [401-450]
Test:    [151-200] [251-300] [351-400] [451-500]

# Princ√≠pios:
‚úÖ Treino sempre ANTES da valida√ß√£o
‚úÖ Gap entre treino e valida√ß√£o (optional)
‚úÖ Test set sempre no futuro
‚ùå Nunca misturar per√≠odos
```

## üö® Data Leakage: O Inimigo Invis√≠vel

### **Tipos de Vazamento** üï≥Ô∏è

| Tipo | Exemplo | Detec√ß√£o | Preven√ß√£o |
|------|---------|----------|-----------|
| **Temporal** | Usar dados futuros | AUC = 1.0 irrealista | Temporal split |
| **Target** | Feature = target | Correla√ß√£o perfeita | EDA cuidadosa |
| **Group** | Mesmo paciente em train/test | Identifiers duplicados | Group-based split |
| **Preprocessing** | Fit scaler em todo dataset | Performance inst√°vel | Pipeline correto |

### **Pipeline Anti-Leakage** üõ°Ô∏è

```python
# ‚ùå ERRADO: Vazamento por preprocessing
scaler.fit(X_all)  # Usa estat√≠sticas do test set!
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ‚úÖ CORRETO: Preprocessing isolado
X_train, X_test = train_test_split(X, y, ...)
scaler.fit(X_train)  # S√≥ estat√≠sticas do treino
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

## üéØ Valida√ß√£o por Tipo de Modelo

### **Classifica√ß√£o** üìä

| Cen√°rio | Estrat√©gia | Configura√ß√£o | M√©tricas Monitoradas |
|---------|------------|--------------|---------------------|
| **Balanceado** | Random K-Fold | k=5, repetitions=3 | Accuracy, F1 |
| **Desbalanceado** | Stratified K-Fold | k=5, repetitions=5 | F1, AUC-ROC, AUC-PR |
| **Multi-classe** | Stratified K-Fold | k=10 | Macro/Micro F1 |
| **Multi-label** | Iterative Split | Custom | Hamming Loss |

### **Regress√£o** üìà

| Cen√°rio | Estrat√©gia | Configura√ß√£o | M√©tricas Monitoradas |
|---------|------------|--------------|---------------------|
| **Linear** | Random K-Fold | k=5 | RMSE, R¬≤ |
| **Time Series** | Time Series CV | 5 splits | MASE, SMAPE |
| **Spatial** | Spatial Block CV | Geographic blocks | Spatial RMSE |
| **Hierarchical** | Group K-Fold | By hierarchy | Grouped MAE |

### **Clustering** üé≠

| Aspecto | Estrat√©gia | Justificativa |
|---------|------------|---------------|
| **Estabilidade** | Bootstrap resampling | Testa robustez |
| **N√∫mero K** | Silhouette CV | Encontra K √≥timo |
| **Algoritmo** | Consensus clustering | M√∫ltiplos algoritmos |
| **Features** | Feature stability | Sensibilidade a features |

## üìè M√©tricas de Qualidade da Divis√£o

### **Distribui√ß√£o e Representatividade** üìä

| M√©trica | F√≥rmula | Interpreta√ß√£o | Threshold |
|---------|---------|---------------|-----------|
| **KS-Test** | $D = \max|F_1(x) - F_2(x)|$ | Diferen√ßa entre distribui√ß√µes | p > 0.05 |
| **Chi-Square** | $\chi^2 = \sum \frac{(O-E)^2}{E}$ | Independ√™ncia categ√≥rica | p > 0.05 |
| **Jensen-Shannon** | $JS = \frac{1}{2}D_{KL}(P||M) + \frac{1}{2}D_{KL}(Q||M)$ | Diverg√™ncia entre distribui√ß√µes | < 0.1 |
| **Wasserstein** | $W_1(P,Q) = \inf_{\gamma} E_{(x,y)\sim\gamma}[|x-y|]$ | Dist√¢ncia entre distribui√ß√µes | < 0.2 |

### **Balanceamento de Classes** ‚öñÔ∏è

```python
# Verifica√ß√£o de estratifica√ß√£o
def check_stratification(y_train, y_test):
    train_dist = y_train.value_counts(normalize=True)
    test_dist = y_test.value_counts(normalize=True)
    max_diff = (train_dist - test_dist).abs().max()
    
    if max_diff < 0.02:  # 2% diferen√ßa
        return "‚úÖ Excelente estratifica√ß√£o"
    elif max_diff < 0.05:  # 5% diferen√ßa
        return "üü° Estratifica√ß√£o aceit√°vel"
    else:
        return "‚ùå Estratifica√ß√£o inadequada"
```

## üîß Implementa√ß√£o Pr√°tica Avan√ßada

### **Pipeline Reproduz√≠vel** üîÑ

```python
from sklearn.model_selection import (
    StratifiedKFold, RepeatedStratifiedKFold,
    TimeSeriesSplit, GroupKFold
)

# Configura√ß√£o para diferentes cen√°rios
splitters = {
    'classification': RepeatedStratifiedKFold(
        n_splits=5, n_repeats=3, random_state=42
    ),
    'regression': KFold(
        n_splits=5, shuffle=True, random_state=42
    ),
    'time_series': TimeSeriesSplit(
        n_splits=5, test_size=30
    ),
    'groups': GroupKFold(n_splits=5)
}
```

### **Valida√ß√£o Aninhada** ü™Ü

```python
# Outer loop: Model assessment
# Inner loop: Hyperparameter tuning
outer_cv = StratifiedKFold(n_splits=5, random_state=42)
inner_cv = StratifiedKFold(n_splits=3, random_state=42)

nested_scores = []
for train_idx, test_idx in outer_cv.split(X, y):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    
    # Inner CV para hyperparameter tuning
    grid_search = GridSearchCV(
        estimator=model, param_grid=params,
        cv=inner_cv, scoring='f1'
    )
    grid_search.fit(X_train, y_train)
    
    # Avaliar no test fold
    best_model = grid_search.best_estimator_
    score = f1_score(y_test, best_model.predict(X_test))
    nested_scores.append(score)

# Score final n√£o enviesado
final_score = np.mean(nested_scores)
```

## üìä Monitoramento e Diagn√≥stico

### **Red Flags na Valida√ß√£o** üö®

| Sinal | Poss√≠vel Causa | Investiga√ß√£o | Corre√ß√£o |
|-------|----------------|--------------|----------|
| **Performance inst√°vel** | Divis√£o inadequada | Analisar vari√¢ncia CV | Mais folds, repeti√ß√µes |
| **Train >> Validation** | Overfitting/leakage | Verificar pipeline | Pipeline correction |
| **Performance irrealista** | Data leakage | EDA temporal | Temporal split |
| **Resultados n√£o reproduziveis** | Random seeds | Verificar seeds | Fix all seeds |

### **M√©tricas de Monitoramento** üìà

```python
# Dashboard de valida√ß√£o
validation_metrics = {
    'cv_mean': np.mean(cv_scores),
    'cv_std': np.std(cv_scores),
    'cv_min': np.min(cv_scores),
    'cv_max': np.max(cv_scores),
    'stability': np.std(cv_scores) / np.mean(cv_scores),
    'train_test_gap': train_score - test_score
}

# Interpreta√ß√£o
if validation_metrics['stability'] < 0.05:
    print("‚úÖ Modelo est√°vel")
elif validation_metrics['train_test_gap'] > 0.1:
    print("‚ö†Ô∏è Poss√≠vel overfitting")
```

## üéØ Estrat√©gias por Tamanho de Dataset

### **Datasets Pequenos (< 1000 amostras)** üîç

| Estrat√©gia | Configura√ß√£o | Justificativa |
|------------|--------------|---------------|
| **LOOCV** | n_splits = n_samples | M√°xima utiliza√ß√£o dos dados |
| **Bootstrap** | n_bootstraps = 1000 | Estimativa robusta |
| **Repeated CV** | k=5, repeats=10 | Reduz vari√¢ncia |

### **Datasets Grandes (> 100k amostras)** üöÄ

| Estrat√©gia | Configura√ß√£o | Vantagem |
|------------|--------------|----------|
| **Simple Split** | 70/15/15 | Computacionalmente eficiente |
| **3-Fold CV** | k=3 | Balance speed/robustez |
| **Sampling** | Subset para CV | Prototipagem r√°pida |

## üîó Integra√ß√£o com Projetos

### **Refer√™ncias Pr√°ticas** üìö

**Divis√£o de Dados Aplicada:**

- üå≥ [**√Årvore de Decis√£o**](https://snowdutra.github.io/Machine-Learning/arvore_decisao/09.divisao_treino_teste):
  - Stratified split para balanceamento
  - CV para pruning optimization
  - Bootstrap para feature importance

- üéØ [**KNN**](https://snowdutra.github.io/Machine-Learning/knn/09.divisao_treino_teste):
  - Stratified CV para K optimization
  - Distance-based validation
  - Neighborhood analysis

- üé≠ [**K-Means**](https://snowdutra.github.io/Machine-Learning/kmeans/09.divisao_treino_teste):
  - Bootstrap para stability
  - Silhouette CV para K selection
  - Consensus clustering validation

## üí° Dicas Avan√ßadas e Melhores Pr√°ticas

### **Para Classifica√ß√£o** üéØ

```python
# Dicas espec√≠ficas
‚úÖ Sempre usar StratifiedKFold para classes desbalanceadas
‚úÖ RepeatedStratifiedKFold para datasets pequenos
‚úÖ GroupKFold quando h√° grupos naturais (pacientes, regi√µes)
‚úÖ Verificar distribui√ß√£o de classes em cada fold
```

### **Para S√©ries Temporais** ‚è∞

```python
# Valida√ß√£o temporal robusta
‚úÖ TimeSeriesSplit com gap temporal
‚úÖ Rolling window para concept drift
‚úÖ M√∫ltiplas janelas de valida√ß√£o
‚úÖ Backtesting com dados hist√≥ricos
```

### **Para Clustering** üé≠

```python
# Valida√ß√£o de clustering
‚úÖ Bootstrap resampling para estabilidade
‚úÖ Cross-validation para n√∫mero K
‚úÖ Consensus clustering para robustez
‚úÖ Perturbation analysis para sensibilidade
```

## üèÜ Checklist de Excel√™ncia

### **Valida√ß√£o Cient√≠fica** ‚úÖ

```python
# Lista de verifica√ß√£o
‚úÖ Seeds fixas para reprodutibilidade
‚úÖ Estratifica√ß√£o para classifica√ß√£o
‚úÖ Pipeline anti-leakage implementado
‚úÖ M√∫ltiplas m√©tricas monitoradas
‚úÖ Intervalos de confian√ßa calculados
‚úÖ An√°lise de estabilidade realizada
‚úÖ Documenta√ß√£o completa da estrat√©gia
‚úÖ Valida√ß√£o final em holdout set
```

### **Qualidade da Divis√£o** üìä

```python
# M√©tricas de qualidade
‚úÖ Distribui√ß√µes similares (KS-test p > 0.05)
‚úÖ Classes balanceadas (<2% diferen√ßa)
‚úÖ Sem data leakage detectado
‚úÖ Performance est√°vel (CV < 5%)
‚úÖ Resultados reproduziveis
‚úÖ Generaliza√ß√£o comprovada
```

> **"Uma divis√£o de dados cientificamente rigorosa √© a diferen√ßa entre um modelo que funciona no laborat√≥rio e um que funciona no mundo real."**

---

*A qualidade da divis√£o de dados determina a confiabilidade de toda a avalia√ß√£o subsequente. Investir tempo nesta etapa √© fundamental para o sucesso do projeto.*