---
hide:
- toc
---

# 04. An√°lise Explorat√≥ria de Dados (EDA) Avan√ßada

---

## EDA: A Arte de Fazer Dados Falarem

A an√°lise explorat√≥ria de dados √© onde **hip√≥teses nascem e intui√ß√µes se confirmam**. √â o momento de transformar n√∫meros brutos em insights acion√°veis que guiar√£o todo o processo de modelagem e avalia√ß√£o.

---

## Objetivos Estrat√©gicos da EDA

### **1. Descoberta de Padr√µes** 

| Tipo de Padr√£o | T√©cnica | Insight Obtido |
|----------------|---------|----------------|
| **Tend√™ncias Temporais** | Time series plots | Sazonalidade, crescimento |
| **Distribui√ß√µes** | Histogramas, Box plots | Normalidade, outliers |
| **Correla√ß√µes** | Heatmaps, Scatter plots | Rela√ß√µes entre vari√°veis |
| **Agrupamentos** | Clustering explorat√≥rio | Segmentos naturais |

### **2. Detec√ß√£o de Problemas** 

| Problema | Sinais | Impacto no Modelo |
|----------|--------|-------------------|
| **Missing Values** | Padr√µes nos NAs | Vi√©s na amostra |
| **Outliers** | Pontos extremos | Distor√ß√£o das m√©tricas |
| **Desbalanceamento** | Distribui√ß√£o skewed | Acur√°cia enganosa |
| **Data Leakage** | Correla√ß√£o perfeita | Overfitting severo |

---

## An√°lise Univariada Avan√ßada

### **Vari√°veis Num√©ricas** 

| Estat√≠stica | F√≥rmula | Interpreta√ß√£o | A√ß√£o Recomendada |
|-------------|---------|---------------|------------------|
| **Skewness** | $\frac{E[(X-\mu)^3]}{\sigma^3}$ | Assimetria da distribui√ß√£o | Transform se \|skew\| > 2 |
| **Kurtosis** | $\frac{E[(X-\mu)^4]}{\sigma^4} - 3$ | "Peso" das caudas | Detectar outliers |
| **Jarque-Bera** | $\frac{n}{6}(S^2 + \frac{(K-3)^2}{4})$ | Teste de normalidade | p < 0.05 = n√£o normal |
| **IQR** | $Q_3 - Q_1$ | Dispers√£o robusta | Outliers se > 1.5√óIQR |

### **An√°lise de Distribui√ß√µes** 

```python
# Identifica√ß√£o de distribui√ß√µes
    Normal: Sim√©trica, sino
    Log-normal: Skew positivo
    Exponencial: Decaimento r√°pido
    Uniforme: Plana
    Bimodal: Dois picos
```

### **Vari√°veis Categ√≥ricas** 

| M√©trica | F√≥rmula | Interpreta√ß√£o |
|---------|---------|---------------|
| **Cardinalidade** | N√∫mero de categorias √∫nicas | Alta = encoding complexo |
| **Frequ√™ncia** | Count/Total | Detectar classes raras |
| **Entropia** | $-\sum p_i \log p_i$ | Diversidade da distribui√ß√£o |
| **Moda** | Categoria mais frequente | Classe dominante |

---

## An√°lise Bivariada e Multivariada

### **Correla√ß√µes e Depend√™ncias**

| Tipo | M√©todo | Range | Interpreta√ß√£o |
|------|--------|-------|---------------|
| **Pearson** | Linear | [-1, 1] | Rela√ß√£o linear |
| **Spearman** | Monot√¥nica | [-1, 1] | Rela√ß√£o ordenada |
| **Kendall** | Concord√¢ncia | [-1, 1] | Robusta a outliers |
| **Cram√©r's V** | Categ√≥rica | [0, 1] | Associa√ß√£o categ√≥rica |

### **Matriz de Correla√ß√£o Interpretada**

```python
# Diretrizes de interpreta√ß√£o
üî¥ |r| > 0.8  : Correla√ß√£o muito forte
üü† |r| > 0.6  : Correla√ß√£o forte  
üü° |r| > 0.4  : Correla√ß√£o moderada
üü¢ |r| > 0.2  : Correla√ß√£o fraca
‚ö™ |r| < 0.2  : Correla√ß√£o neglig√≠vel
```

### **An√°lise de Intera√ß√µes**

| T√©cnica | Prop√≥sito | Quando Usar |
|---------|-----------|-------------|
| **Feature Crosses** | Capturar intera√ß√µes | Features complementares |
| **Polynomial Features** | Rela√ß√µes n√£o-lineares | Curvatura nos dados |
| **Binning + Encoding** | Discretiza√ß√£o | Rela√ß√µes complexas |

---

## An√°lise por Tipo de Problema

### **Classifica√ß√£o** 

#### **An√°lise da Vari√°vel Target** 

```python
# Distribui√ß√£o de classes
Class 0: 35% (105 samples) üî¥
Class 1: 65% (195 samples) üü¢
Ratio: 1.86:1 

# M√©tricas de desbalanceamento
Imbalance Ratio: 1.86
Entropy: 0.934 (m√°ximo = 1.0)
Gini Index: 0.455
```

#### **An√°lise por Classe** 

| Feature | Classe 0 (M√©dia) | Classe 1 (M√©dia) | Separabilidade |
|---------|------------------|------------------|----------------|
| Math Score | 58.3 ¬± 15.2 | 72.1 ¬± 12.8 | ‚≠ê‚≠ê‚≠ê |
| Reading Score | 61.2 ¬± 14.1 | 75.8 ¬± 11.9 | ‚≠ê‚≠ê‚≠ê |
| Writing Score | 59.7 ¬± 14.8 | 74.2 ¬± 12.2 | ‚≠ê‚≠ê‚≠ê |

### **Clustering** 

#### **An√°lise de Agrupabilidade** 

| Teste | Valor | Interpreta√ß√£o |
|-------|-------|---------------|
| **Hopkins Statistic** | 0.23 | Dados agrup√°veis (< 0.5) |
| **Variance Ratio** | 0.67 | Estrutura moderada |
| **Gap Statistic** | K=3 | N√∫mero √≥timo de clusters |

#### **Estrutura dos Dados** 

```python
# M√©tricas de densidade
    Densidade m√©dia: 0.67
    Dist√¢ncia m√©dia: 2.34
    Silhouette: 0.47 (moderado)
    Calinski-Harabasz: 156.8
```


---

## Visualiza√ß√µes Avan√ßadas

### **Gr√°ficos Univariados** 

| Tipo | Prop√≥sito | Quando Usar |
|------|-----------|-------------|
| **Violin Plot** | Distribui√ß√£o + densidade | Comparar grupos |
| **Box Plot** | Mediana + outliers | Detectar anomalias |
| **Histogram** | Frequ√™ncia | Entender distribui√ß√£o |
| **Q-Q Plot** | Normalidade | Verificar suposi√ß√µes |

### **Gr√°ficos Multivariados** 

| Tipo | Dimens√µes | Insight |
|------|-----------|---------|
| **Scatter Matrix** | n √ó n | Correla√ß√µes pairwise |
| **Parallel Coordinates** | Multi-dimensional | Padr√µes em alta dimens√£o |
| **Radar Chart** | M√∫ltiplas m√©tricas | Perfil multivariado |
| **Heatmap** | Correla√ß√£o | Rela√ß√µes estruturadas |

### **Visualiza√ß√µes Interativas** 

```python
# Plotly para interatividade
    Zoom, pan, hover
    Brush selection
    Dropdown filters
    Responsive design
```

---

## Red Flags na EDA

### **Sinais de Alerta** 

| Problema | Sinal Visual | M√©trica | A√ß√£o Corretiva |
|----------|--------------|---------|----------------|
| **Perfect Separation** | Clusters distintos | Silhouette = 1.0 | Verificar data leakage |
| **No Variation** | Linha plana | Std = 0 | Remover feature |
| **Extreme Skew** | Cauda longa | \|Skew\| > 3 | Transforma√ß√£o log |
| **Too Many Outliers** | Pontos dispersos | >5% fora 3œÉ | Investigar fonte |

### **Checklist de Qualidade** 

```python
    Missing values < 5%
    Outliers identificados e explicados
    Features correlacionadas (|r| > 0.9) removidas
    Distribui√ß√£o target balanceada ou tratada
    No data leakage detectado
    Features t√™m variabilidade suficiente
    Escalas das features compat√≠veis
```

---

## EDA Automatizada e Ferramentas

### **Bibliotecas Profissionais** 

| Ferramenta | Foco | Vantagem |
|------------|------|----------|
| **Pandas Profiling** | Relat√≥rio completo | Autom√°tico, r√°pido |
| **Sweetviz** | Compara√ß√£o datasets | Visual, intuitivo |
| **Autoviz** | Visualiza√ß√µes inteligentes | ML-powered |
| **DataPrep** | Pipeline completo | Escal√°vel |

### **M√©tricas Automatizadas** 

```python
# Report autom√°tico
data_quality_score = 0.87  # Excelente > 0.8
missing_data_ratio = 0.02  # Aceit√°vel < 0.05
correlation_strength = 0.65  # Moderada
outlier_percentage = 0.03  # Normal < 0.05
```

---

## EDA Espec√≠fica por Algoritmo

### **Para KNN** 

| Aspecto | An√°lise | Impacto |
|---------|---------|---------|
| **Escala** | Range das features | Dist√¢ncias distorcidas |
| **Dimensionalidade** | N√∫mero de features | Curse of dimensionality |
| **Ru√≠do** | Outliers locais | Vizinhos inadequados |
| **Densidade** | Distribui√ß√£o espacial | Performance heterog√™nea |

### **Para K-Means** 

| Aspecto | An√°lise | Impacto |
|---------|---------|---------|
| **Forma dos Clusters** | Elipses vs c√≠rculos | Centroides inadequados |
| **Tamanhos** | Variabilidade | Vi√©s para clusters grandes |
| **Separa√ß√£o** | Dist√¢ncia entre grupos | Dificuldade de converg√™ncia |
| **Linearidade** | PCA components | Redu√ß√£o de dimensionalidade |

---

## Integra√ß√£o com Projetos

### **Refer√™ncias Pr√°ticas** 

An√°lise Explorat√≥ria Aplicada:

[**√Årvore de Decis√£o**](https://snowdutra.github.io/Machine-Learning/arvore_decisao/04.analise_exploratoria):
  
  - An√°lise de import√¢ncia de features
  
  - Detec√ß√£o de interactions
  
  - Visualiza√ß√£o de splits

[**KNN**](https://snowdutra.github.io/Machine-Learning/knn/04.analise_exploratoria):
  
  - An√°lise de densidade local
  
  - Mapeamento de vizinhan√ßas
  
  - Impacto da dimensionalidade

[**K-Means**](https://snowdutra.github.io/Machine-Learning/kmeans/04.analise_exploratoria):
  
  - Identifica√ß√£o de clusters naturais
  
  - An√°lise de separabilidade
  
  - Otimiza√ß√£o do n√∫mero K

---

## Insights Acion√°veis

### **Para Melhorar Modelos** 

```python
# Baseado na EDA
    Features mais discriminativas identificadas
    Estrat√©gia de balanceamento definida
    Transforma√ß√µes necess√°rias mapeadas
    M√©tricas de avalia√ß√£o apropriadas escolhidas
    N√∫mero √≥timo de clusters estimado
```

### **Para Comunica√ß√£o**

```python
# Storytelling com dados
    Tend√™ncias identificadas
    Visualiza√ß√µes impactantes
    Estat√≠sticas convincentes
    Insights surprendentes
    Recomenda√ß√µes baseadas em evid√™ncias
```

> **"EDA n√£o √© apenas sobre conhecer os dados - √© sobre deixar os dados revelarem suas verdades ocultas e guiarem suas decis√µes de modelagem."**

---

*Uma EDA meticulosa √© o que transforma um projeto de Machine Learning de "tentativa e erro" em uma abordagem cient√≠fica e direcionada.*