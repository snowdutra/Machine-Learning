{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9250606",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação em Machine Learning\n",
    "\n",
    "Neste notebook, vamos abordar as principais métricas utilizadas para avaliar o desempenho de modelos de Machine Learning, tanto para tarefas de classificação quanto de regressão.\n",
    "\n",
    "A escolha da métrica correta é fundamental para interpretar os resultados e tomar decisões sobre ajustes e melhorias nos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2514c9",
   "metadata": {},
   "source": [
    "## 6.1. Classificação\n",
    "\n",
    "As métricas de classificação avaliam o desempenho de modelos que predizem rótulos de classe. Abaixo estão as principais métricas utilizadas:\n",
    "\n",
    "| Métrica              | Propósito                                                                 | Fórmula                                   | Caso de Uso                                      |\n",
    "|----------------------|---------------------------------------------------------------------------|-------------------------------------------|--------------------------------------------------|\n",
    "| **Acurácia**         | Proporção de previsões corretas em todas as classes                      | $\\frac{TP + TN}{TP + TN + FP + FN}$      | Útil para conjuntos balanceados                  |\n",
    "| **Precisão**         | Proporção de positivos previstos que são realmente corretos               | $\\frac{TP}{TP + FP}$                     | Importante quando falsos positivos são custosos   |\n",
    "| **Recall (Sensibilidade)** | Proporção de positivos reais corretamente identificados           | $\\frac{TP}{TP + FN}$                     | Importante quando falsos negativos são custosos   |\n",
    "| **F1-Score**         | Média harmônica entre precisão e recall                                   | $2 \\cdot \\frac{Precisão \\cdot Recall}{Precisão + Recall}$ | Útil para dados desbalanceados                  |\n",
    "| **AUC-ROC**          | Avalia a capacidade do modelo de distinguir entre classes                 | Área sob a curva ROC                      | Efetivo para classificação binária               |\n",
    "| **AUC-PR**           | Avalia o trade-off entre precisão e recall                                | Área sob a curva Precision-Recall         | Preferido quando classe positiva é rara           |\n",
    "| **Matriz de Confusão** | Resumo tabular dos resultados de previsão (TP, TN, FP, FN)               | -                                         | Detalha desempenho por classe                    |\n",
    "| **Hamming Loss**     | Fração de rótulos incorretos sobre o total                                | $\\frac{1}{N} \\sum_{i=1}^N \\frac{1}{L} \\sum_{j=1}^L 1(y_{ij} \\neq \\hat{y}_{ij})$ | Útil para classificação multi-label         |\n",
    "| **Balanced Accuracy**| Média do recall por classe, útil para dados desbalanceados                | $\\frac{1}{C} \\sum_{i=1}^C \\frac{TP_i}{TP_i + FN_i}$ | Efetivo para problemas com classes desbalanceadas |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae1dd2",
   "metadata": {},
   "source": [
    "## 6.2. Regressão\n",
    "\n",
    "As métricas de regressão avaliam o desempenho de modelos que predizem valores contínuos. Veja as principais métricas:\n",
    "\n",
    "| Métrica                        | Propósito                                                        | Fórmula                                               | Caso de Uso                                         |\n",
    "|--------------------------------|------------------------------------------------------------------|-------------------------------------------------------|-----------------------------------------------------|\n",
    "| **Erro Absoluto Médio (MAE)**  | Média das diferenças absolutas entre predições e valores reais   | $\\frac{1}{N} \\sum_{i=1}^N |y_i - \\hat{y}_i|$      | Robusto a outliers, fácil de interpretar            |\n",
    "| **Erro Quadrático Médio (MSE)**| Média das diferenças quadráticas entre predições e valores reais | $\\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2$      | Sensível a outliers, comum em redes neurais         |\n",
    "| **Raiz do Erro Quadrático Médio (RMSE)** | Raiz quadrada do MSE, erro na mesma unidade do alvo | $\\sqrt{\\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2}$ | Preferido para magnitude de erro interpretável       |\n",
    "| **Erro Percentual Absoluto Médio (MAPE)**| Média percentual do erro relativo aos valores reais | $\\frac{1}{N} \\sum_{i=1}^N \\left|\\frac{y_i - \\hat{y}_i}{y_i}\\right| \\cdot 100$ | Útil quando erros relativos importam                 |\n",
    "| **$R^2$ (Coeficiente de Determinação)**   | Proporção da variância explicada pelo modelo        | $1 - \\frac{\\sum_{i=1}^N (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2}$ | Indica ajuste do modelo, valores próximos de 1 são melhores |\n",
    "| **$R^2$ Ajustado**             | Ajusta o $R^2$ para número de preditores, penaliza modelos complexos | $1 - \\left(\\frac{(1 - R^2)(N - 1)}{N - k - 1}\\right)$ | Útil para comparar modelos com diferentes números de variáveis |\n",
    "| **Erro Absoluto Mediano (MedAE)** | Mediana das diferenças absolutas, robusto a outliers | $\\text{median}(|y_1 - \\hat{y}_1|, \\ldots, |y_N - \\hat{y}_N|)$ | Preferido em dados com valores extremos ou erros não gaussianos |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6677dfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Avaliação do KNN ---\n",
      "Acurácia: 0.62\n",
      "Precisão: 0.6768558951965066\n",
      "Recall: 0.7948717948717948\n",
      "F1-Score: 0.7311320754716981\n",
      "Matriz de Confusão:\n",
      " [[ 31  74]\n",
      " [ 40 155]]\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.30      0.35       105\n",
      "           1       0.68      0.79      0.73       195\n",
      "\n",
      "    accuracy                           0.62       300\n",
      "   macro avg       0.56      0.55      0.54       300\n",
      "weighted avg       0.59      0.62      0.60       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do modelo KNN\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "y_test = pd.read_csv('knn_y_test.csv').values.ravel()\n",
    "y_pred = pd.read_csv('knn_y_pred.csv').values.ravel()\n",
    "\n",
    "print('--- Avaliação do KNN ---')\n",
    "print('Acurácia:', accuracy_score(y_test, y_pred))\n",
    "print('Precisão:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1-Score:', f1_score(y_test, y_pred))\n",
    "print('Matriz de Confusão:\\n', confusion_matrix(y_test, y_pred))\n",
    "print('Relatório de Classificação:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46d253c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Avaliação do K-Means ---\n",
      "Silhouette Score: 0.47410805799440514\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do modelo K-Means\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "X = pd.read_csv('kmeans_X.csv').values\n",
    "clusters = pd.read_csv('kmeans_clusters.csv').values.ravel()\n",
    "\n",
    "print('--- Avaliação do K-Means ---')\n",
    "print('Silhouette Score:', silhouette_score(X, clusters))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
