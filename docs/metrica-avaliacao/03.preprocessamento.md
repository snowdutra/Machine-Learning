---
hide:
- toc
---

# Pré-processamento Avançado para Avaliação Robusta

----

## A Fundação do Sucesso em ML

O pré-processamento não é apenas "limpeza de dados" - é a **engenharia de fundação** que determina o sucesso ou fracasso de qualquer modelo de Machine Learning. Dados mal processados podem tornar até mesmo o algoritmo mais sofisticado inútil.

---

## Impacto Direto na Avaliação

### **Por que o Pré-processamento Afeta as Métricas?**

```python
# ANTES: Dados sem tratamento
Acurácia: 0.62
F1-Score: 0.73
AUC-ROC: 0.65

# DEPOIS: Dados adequadamente processados
Acurácia: 0.87  (+40%)
F1-Score: 0.87  (+19%)
AUC-ROC: 0.92   (+42%)
```

---

## Técnicas Fundamentais

### **1. Limpeza de Dados** 

| Problema | Técnica | Impacto na Avaliação |
|----------|---------|---------------------|
| **Valores Ausentes** | Imputação inteligente | Evita viés nas métricas |
| **Duplicatas** | Deduplicação | Previne data leakage |
| **Outliers** | Detecção IQR/Z-score | Melhora robustez |
| **Inconsistências** | Padronização de formato | Reduz ruído |

### **2. Transformações Numéricas** 

| Transformação | Quando Usar | Algoritmos Beneficiados |
|---------------|-------------|------------------------|
| **Normalização** (Min-Max) | Features em escalas diferentes | KNN, SVM, Redes Neurais |
| **Padronização** (Z-score) | Distribuições normais | PCA, Logistic Regression |
| **Robust Scaling** | Presença de outliers | Dados financeiros, sensores |
| **Power Transform** | Distribuições assimétricas | Yeo-Johnson, Box-Cox |

### **3. Encoding de Variáveis Categóricas** 

| Técnica | Cardinalidade | Vantagem | Desvantagem |
|---------|---------------|----------|-------------|
| **One-Hot** | Baixa (<10) | Interpretável | Curse of dimensionality |
| **Label Encoding** | Qualquer | Eficiente | Implica ordem |
| **Target Encoding** | Alta | Captura relação com target | Risco de overfitting |
| **Binary Encoding** | Muito alta | Reduz dimensões | Menos interpretável |

---

## Tratamento de Desbalanceamento

### **Técnicas de Balanceamento**

| Abordagem | Técnica | Quando Usar | Prós | Contras |
|-----------|---------|-------------|------|---------|
| **Undersampling** | Random/Tomek Links | Dados abundantes | Rápido | Perda de informação |
| **Oversampling** | SMOTE/ADASYN | Dados limitados | Preserva informação | Risco de overfitting |
| **Híbrido** | SMOTEENN | Balanceado | Melhor qualidade | Mais complexo |
| **Algorithmic** | Class weights | Qualquer cenário | Simples | Dependente do algoritmo |

### **Estratégias por Nível de Desbalanceamento** 

```python
# Leve (1:2 a 1:4)
Stratified sampling
Class weights

# Moderado (1:5 a 1:20)  
SMOTE + Undersampling
Ensemble methods

# Severo (1:100+)
Anomaly detection
One-class classification
Cost-sensitive learning
```

---

## Feature Engineering para Melhor Avaliação

### **Criação de Features** 

| Tipo | Exemplo | Benefício |
|------|---------|-----------|
| **Polinomiais** | $x_1 \times x_2$, $x_1^2$ | Captura interações |
| **Temporais** | dia_semana, trimestre | Padrões sazonais |
| **Agregações** | média_por_grupo | Contexto estatístico |
| **Ratio Features** | $\frac{vendas}{estoque}$ | Normalização natural |

### **Seleção de Features**

| Método | Tipo | Vantagem | Limitação |
|--------|------|----------|-----------|
| **Filter** | Correlação, Chi² | Rápido | Ignora interações |
| **Wrapper** | RFE, Forward Selection | Considera modelo | Computacionalmente caro |
| **Embedded** | Lasso, Random Forest | Balanceado | Específico do algoritmo |

---

## Pipeline de Pré-processamento

### **Sequência Recomendada**

```python
1.Análise Exploratória
   ├── Distribuições
   ├── Missing values
   ├── Outliers
   └── Correlações

2.Limpeza Básica
   ├── Remoção duplicatas
   ├── Tratamento missing
   └── Correção tipos

3.Transformações
   ├── Encoding categóricas
   ├── Scaling numérico
   └── Feature engineering

4.Balanceamento
   ├── Análise desbalanceamento
   ├── Aplicação técnica
   └── Validação resultado

5.Validação Pipeline
   ├── Train/validation/test split
   ├── Cross-validation
   └── Detecção data leakage
```

### **Data Leakage: O Inimigo Silencioso** 

| Tipo | Exemplo | Como Detectar | Como Prevenir |
|------|---------|---------------|---------------|
| **Temporal** | Usar dados futuros | Performance irrealista | Split temporal |
| **Target** | Feature correlaciona perfeitamente | Correlação = 1.0 | Análise de correlação |
| **Duplicação** | Mesmo registro em train/test | Linhas idênticas | Deduplicação antes split |

---

## Validação do Pré-processamento

### **Checklist de Qualidade** 

| Verificação | Critério | Ferramenta |
|-------------|----------|------------|
| **Distribuições** | Similaridade train/test | KS-test, histogramas |
| **Missing Values** | < 5% ou imputado | `df.isnull().sum()` |
| **Outliers** | Identificados e tratados | IQR, Z-score |
| **Scaling** | Média ≈ 0, Std ≈ 1 | `df.describe()` |
| **Encoding** | Sem vazamento de info | Cross-validation |

### **Métricas de Qualidade dos Dados** 

```python
# Completude
completeness = 1 - (missing_values / total_values)

# Consistência  
consistency = valid_records / total_records

# Acurácia dos dados
data_accuracy = correct_values / total_values

# Unicidade
uniqueness = unique_records / total_records
```

---

## Automatização e Reprodutibilidade

### **Pipeline Automatizado** 

```python
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# Pipeline reproduzível
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numeric_features),
    ('cat', OneHotEncoder(drop='first'), categorical_features)
])

# Pipeline completo
ml_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('balancer', SMOTE(random_state=42)),
    ('classifier', KNeighborsClassifier())
])
```

### **Versionamento de Transformações**

| Aspecto | Ferramenta | Benefício |
|---------|------------|-----------|
| **Código** | Git | Rastreabilidade |
| **Dados** | DVC | Reprodutibilidade |
| **Modelos** | MLflow | Comparabilidade |
| **Pipelines** | Kedro | Modularidade |

---

## Integração com Projetos Específicos

### **Referências Práticas** 

Pré-processamento Aplicado:

[**Árvore de Decisão**](https://snowdutra.github.io/Machine-Learning/arvore_decisao/08.preprocessamento): 
  
  - Tratamento de missing values
  
  - Feature engineering para splits
  
  - Balanceamento de classes

[**KNN**](https://snowdutra.github.io/Machine-Learning/knn/08.preprocessamento):
 
  - Normalização crítica para distâncias
  
  - Redução de dimensionalidade
  
  - Tratamento de outliers

[**K-Means**](https://snowdutra.github.io/Machine-Learning/kmeans/08.preprocessamento):
  
  - Padronização obrigatória
  
  - Seleção de features relevantes
  
  - Tratamento de ruído

---

## Dicas Avançadas

### **Para Classificação** 
- Use **stratified sampling** para manter proporções
- Aplique **SMOTE** apenas no conjunto de treino
- Valide **calibração** das probabilidades

### **Para Clustering** 
- **Padronize sempre** - distâncias são sensíveis à escala
- Considere **PCA** para redução de dimensionalidade
- Teste **diferentes métricas** de distância

### **Para Séries Temporais** 
- **Split temporal** obrigatório
- **Feature engineering** baseado em lags
- **Stationarity** tests antes do modeling

> **"Dados ruins produzem modelos ruins, independentemente do algoritmo. Dados bem processados podem tornar até algoritmos simples efetivos."**

---

*Um pré-processamento meticuloso é o que separa projetos acadêmicos de soluções profissionais de Machine Learning.*